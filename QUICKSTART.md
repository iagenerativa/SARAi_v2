# ğŸš€ SARAi v2 - Inicio RÃ¡pido

## InstalaciÃ³n en 3 pasos

```bash
# 1. Ejecutar instalador
bash install.sh

# 2. Activar entorno
source venv/bin/activate

# 3. Iniciar SARAi
python main.py
```

## Primera vez (Modo Simulado)

El sistema usa TRM-Classifier **simulado** basado en keywords. Esto permite probar el sistema inmediatamente sin entrenar modelos.

```bash
python main.py
```

Ejemplo:
```
TÃº: Â¿CÃ³mo configuro SSH en Linux?
ğŸ“Š Intent: hard=0.92, soft=0.15
âš–ï¸  Pesos: Î±=0.95 (hard), Î²=0.05 (soft)
ğŸ”¬ Usando Expert Agent (SOLAR-10.7B)...
```

## Entrenar TRM Real (Opcional)

Para mejor clasificaciÃ³n, entrena el TRM:

```bash
# 1. Generar dataset
python scripts/generate_synthetic_data.py --samples 1000

# 2. Entrenar
python scripts/train_trm.py --data data/trm_training.json --epochs 50

# 3. Usar TRM entrenado
python main.py --use-real-trm
```

## Comandos Ãštiles

```bash
# Ver estadÃ­sticas de rendimiento
python main.py --stats

# Ver estadÃ­sticas de Ãºltimos 30 dÃ­as
python main.py --stats --days 30

# Ejecutar tests
python -m pytest tests/ -v

# Limpiar logs antiguos
find logs/ -name "*.jsonl" -mtime +30 -delete
```

## GestiÃ³n de Memoria

SARAi gestiona memoria automÃ¡ticamente, pero puedes optimizar:

**Para sistemas con <12GB RAM disponible:**

Edita `config/models.yaml`:
```yaml
memory:
  max_concurrent_llms: 1  # Solo 1 LLM en RAM a la vez
```

**Para acelerar respuestas (sacrificando memoria):**

```yaml
memory:
  unload_timeout_seconds: 300  # Mantener modelos 5 min en RAM
```

## Estructura Simplificada

```
SARAi_v2/
â”œâ”€â”€ main.py              â† Punto de entrada
â”œâ”€â”€ config/models.yaml   â† ConfiguraciÃ³n
â”œâ”€â”€ core/                â† Componentes principales
â”œâ”€â”€ agents/              â† Agentes LLM
â”œâ”€â”€ logs/                â† Historial de interacciones
â””â”€â”€ README.md            â† DocumentaciÃ³n completa
```

## Troubleshooting RÃ¡pido

### Error: "Out of memory"
```bash
# Reducir carga en config/models.yaml
memory:
  max_concurrent_llms: 1
```

### Los modelos se descargan lentamente
```bash
# Usar mirror de HuggingFace
export HF_ENDPOINT=https://hf-mirror.com
python main.py
```

### Quiero respuestas mÃ¡s rÃ¡pidas
Usa solo el tiny agent editando `core/graph.py` lÃ­nea 89:
```python
if state["alpha"] > 0.95:  # Solo expert en casos extremos
```

## PrÃ³ximos Pasos

1. âœ… **Prueba el sistema** con `python main.py`
2. ğŸ“Š **Acumula interacciones** (el sistema aprende del feedback)
3. ğŸ“ **Entrena el TRM** tras ~100 interacciones
4. ğŸ§  **Activa modo learned** en el MCP

---

**Â¿Necesitas ayuda?** Consulta `README.md` para documentaciÃ³n completa.
