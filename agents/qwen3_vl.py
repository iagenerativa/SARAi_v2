"""
Qwen3-VL-4B Vision Agent - Best-of-Breed Specialist
====================================================

Especialista en an√°lisis de imagen y video usando Qwen3-VL-4B Q6_K (6-bit).

Modelo: NexaAI/Qwen3-VL-4B-Instruct-GGUF (Q6_K)
- Tama√±o: ~3.3 GB VRAM
- Cuantizaci√≥n: Q6_K (6-bit, mejor calidad que Q4)
- First-token: ~500ms (vs ~700ms Omni-7B)

Benchmarks (vs Qwen2.5-Omni-7B):
- MMMU: 60.1% vs 59.2% (+0.9pp)
- MVBench: 71.9% vs 70.3% (+1.6pp)
- Video-MME: 65.8% vs 64.3% (+1.5pp)
- VRAM: 3.3 GB vs 4.9 GB (-33%)
- First-token: ~500ms vs ~700ms (-29%)

Documentaci√≥n oficial:
- https://github.com/QwenLM/Qwen3-VL/tree/main/qwen-vl-utils
- process_vision_info(): image_patch_size=16, return_video_metadata=True

Author: SARAi v2.16.1 Best-of-Breed
"""

import os
import yaml
from pathlib import Path
from typing import Dict, List, Optional, Union, Any
from dataclasses import dataclass
import logging

# LangChain imports (compatible con m√∫ltiples versiones)
try:
    from langchain_community.llms import LlamaCpp
except ImportError:
    from langchain.llms import LlamaCpp

try:
    from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
except ImportError:
    from langchain.schema import BaseMessage, HumanMessage, AIMessage

# Qwen3-VL utils
try:
    from qwen_vl_utils import process_vision_info
    QWEN_VL_UTILS_AVAILABLE = True
except ImportError:
    QWEN_VL_UTILS_AVAILABLE = False
    logging.warning("qwen-vl-utils not found. Install with: pip install qwen-vl-utils")

from transformers import AutoProcessor

logger = logging.getLogger(__name__)


@dataclass
class Qwen3VLConfig:
    """
    Configuraci√≥n para Qwen3-VL-4B Agent
    
    Patr√≥n estandarizado Best-of-Breed (igual que OmniConfig):
    - model_path: Ruta GGUF local
    - n_ctx: Context window (default 2048)
    - n_threads: CPU threads (auto-detect)
    - temperature: Sampling (0.3 para visi√≥n precisa)
    - max_tokens: L√≠mite de respuesta
    - permanent: False (bajo demanda con TTL)
    """
    model_path: str
    n_ctx: int = 2048
    n_threads: int = 6
    temperature: float = 0.3
    max_tokens: int = 512
    permanent: bool = False
    ttl_seconds: int = 60
    
    @classmethod
    def from_yaml(cls, config_path: str = "config/sarai.yaml"):
        """Carga configuraci√≥n desde sarai.yaml (patr√≥n Best-of-Breed)"""
        import os
        
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        vision = config['models']['qwen3_vl_4b']
        runtime = config.get('runtime', {})
        
        return cls(
            model_path=str(Path("models/gguf") / vision['gguf_file']),
            n_ctx=vision.get('context_length', 2048),
            n_threads=runtime.get('n_threads', max(1, os.cpu_count() - 2)),
            temperature=vision.get('temperature', 0.3),
            max_tokens=vision.get('max_tokens', 512),
            permanent=vision.get('permanent', False),
            ttl_seconds=vision.get('ttl_seconds', 60)
        )


class Qwen3VLAgent:
    """
    Vision Agent usando Qwen3-VL-4B con GGUF + LangChain
    
    Features:
    - Imagen: Local path, URL, base64, PIL.Image
    - Video: Local path, frames extra√≠dos, control de FPS
    - Ajuste din√°mico de resoluci√≥n (resized_height, resized_width)
    - Metadata de video (return_video_metadata=True)
    - Image patch size configurable (default: 16)
    
    Usage:
        agent = Qwen3VLAgent()
        
        # Imagen local
        response = agent.invoke_vision(
            prompt="Describe this image",
            image_path="/path/to/image.jpg"
        )
        
        # Video con FPS custom
        response = agent.invoke_vision(
            prompt="Describe this video",
            video_path="/path/to/video.mp4",
            fps=2.0,
            resized_height=280,
            resized_width=280
        )
    """
    
    def __init__(self, config: Optional[Qwen3VLConfig] = None):
        """
        Inicializa el vision agent.
        
        Args:
            config: Configuraci√≥n del modelo. Si es None, carga desde sarai.yaml
        """
        self.config = config or Qwen3VLConfig.from_yaml()
        self.model: Optional[LlamaCpp] = None
        self.processor: Optional[AutoProcessor] = None
        self.image_patch_size = 16  # Qwen3-VL default
        
        logger.info(f"üé® Qwen3-VL-4B Agent inicializado (config cargado)")
    
    def _load_model(self):
        """Lazy loading del modelo GGUF"""
        if self.model is not None:
            return
        
        # Construir path al GGUF
        gguf_path = Path("models/gguf") / self.config.gguf_file
        
        if not gguf_path.exists():
            raise FileNotFoundError(
                f"GGUF no encontrado: {gguf_path}\n"
                f"Descarga con:\n"
                f"  huggingface-cli download {self.config.repo_id} "
                f"--include '{self.config.gguf_file}' "
                f"--local-dir models/gguf/ --local-dir-use-symlinks False"
            )
        
        logger.info(f"üîÑ Cargando Qwen3-VL-4B desde {gguf_path}")
        
        # LangChain LlamaCpp wrapper
        self.model = LlamaCpp(
            model_path=str(gguf_path),
            n_ctx=self.config.n_ctx,
            n_threads=self.config.n_threads,
            verbose=False,
            use_mmap=True,
            use_mlock=False  # CR√çTICO: evita OOM
        )
        
        # Cargar processor para process_vision_info
        if QWEN_VL_UTILS_AVAILABLE:
            self.processor = AutoProcessor.from_pretrained(self.config.repo_id)
        
        logger.info(f"‚úÖ Qwen3-VL-4B cargado ({self.config.memory_mb} MB)")
    
    def _prepare_vision_messages(
        self,
        prompt: str,
        image_path: Optional[str] = None,
        video_path: Optional[str] = None,
        fps: Optional[float] = None,
        resized_height: Optional[int] = None,
        resized_width: Optional[int] = None
    ) -> List[Dict]:
        """
        Prepara mensajes en formato Qwen3-VL seg√∫n documentaci√≥n oficial.
        
        Soporta:
        - image: "file:///path", "http://url", "data:image;base64,...", PIL.Image
        - video: "file:///path/video.mp4" o ["frame1.jpg", "frame2.jpg", ...]
        - Resize din√°mico: resized_height, resized_width
        - FPS control: fps (frames por segundo)
        
        Returns:
            List[Dict]: Mensajes en formato Qwen3-VL
        """
        content = []
        
        # A√±adir imagen si se proporciona
        if image_path:
            image_item = {
                "type": "image",
                "image": f"file://{os.path.abspath(image_path)}"
            }
            
            # Resize opcional
            if resized_height and resized_width:
                image_item["resized_height"] = resized_height
                image_item["resized_width"] = resized_width
            
            content.append(image_item)
        
        # A√±adir video si se proporciona
        if video_path:
            video_item = {
                "type": "video",
                "video": f"file://{os.path.abspath(video_path)}"
            }
            
            # FPS opcional
            if fps:
                video_item["fps"] = fps
            
            # Resize opcional
            if resized_height and resized_width:
                video_item["resized_height"] = resized_height
                video_item["resized_width"] = resized_width
            
            content.append(video_item)
        
        # A√±adir prompt de texto
        content.append({
            "type": "text",
            "text": prompt
        })
        
        return [{"role": "user", "content": content}]
    
    def invoke_vision(
        self,
        prompt: str,
        image_path: Optional[str] = None,
        video_path: Optional[str] = None,
        fps: Optional[float] = 2.0,
        resized_height: Optional[int] = None,
        resized_width: Optional[int] = None,
        max_tokens: int = 1024
    ) -> str:
        """
        Invoca el modelo Qwen3-VL con imagen/video.
        
        Args:
            prompt: Pregunta o instrucci√≥n sobre la imagen/video
            image_path: Path a imagen local (opcional)
            video_path: Path a video local (opcional)
            fps: Frames por segundo para video (default: 2.0)
            resized_height: Alto de resize (opcional, auto si None)
            resized_width: Ancho de resize (opcional, auto si None)
            max_tokens: Tokens m√°ximos a generar
        
        Returns:
            str: Respuesta del modelo
        
        Raises:
            ValueError: Si no se proporciona ni imagen ni video
            FileNotFoundError: Si el modelo GGUF no existe
        
        Example:
            >>> agent = Qwen3VLAgent()
            >>> response = agent.invoke_vision(
            ...     prompt="¬øQu√© objetos ves en esta imagen?",
            ...     image_path="/path/to/image.jpg"
            ... )
            >>> print(response)
        """
        if not image_path and not video_path:
            raise ValueError("Debe proporcionar al menos image_path o video_path")
        
        # Lazy loading
        self._load_model()
        
        # Preparar mensajes en formato Qwen3-VL
        messages = self._prepare_vision_messages(
            prompt=prompt,
            image_path=image_path,
            video_path=video_path,
            fps=fps,
            resized_height=resized_height,
            resized_width=resized_width
        )
        
        # Procesar visi√≥n con qwen_vl_utils (si est√° disponible)
        if QWEN_VL_UTILS_AVAILABLE and self.processor:
            # Aplicar chat template
            text = self.processor.apply_chat_template(
                messages,
                tokenize=False,
                add_generation_prompt=True
            )
            
            # Procesar informaci√≥n visual
            images, videos, video_kwargs = process_vision_info(
                messages,
                image_patch_size=self.image_patch_size,
                return_video_kwargs=True,
                return_video_metadata=True
            )
            
            # Extraer metadata de video si existe
            if videos is not None:
                videos, video_metadatas = zip(*videos)
                videos = list(videos)
                video_metadatas = list(video_metadatas)
            else:
                video_metadatas = None
            
            # Log info
            logger.info(f"üì∏ Procesando visi√≥n: images={images is not None}, videos={videos is not None}")
            if video_kwargs:
                logger.info(f"üé¨ Video kwargs: {video_kwargs}")
        
        else:
            # Fallback: construcci√≥n manual del prompt
            text = self._build_fallback_prompt(messages)
        
        # Generar respuesta
        logger.info(f"ü§ñ Generando respuesta (max_tokens={max_tokens})")
        response = self.model.invoke(text, max_tokens=max_tokens)
        
        return response.strip()
    
    def _build_fallback_prompt(self, messages: List[Dict]) -> str:
        """
        Fallback cuando qwen-vl-utils no est√° disponible.
        Construye prompt manualmente.
        """
        parts = []
        for msg in messages:
            for item in msg["content"]:
                if item["type"] == "image":
                    parts.append(f"[IMAGE: {item['image']}]")
                elif item["type"] == "video":
                    parts.append(f"[VIDEO: {item['video']}]")
                elif item["type"] == "text":
                    parts.append(item["text"])
        
        return "\n".join(parts)
    
    def unload(self):
        """Descarga el modelo de memoria"""
        if self.model:
            del self.model
            self.model = None
            logger.info("üóëÔ∏è Qwen3-VL-4B descargado de memoria")


# Singleton global (opcional)
_qwen3_vl_agent: Optional[Qwen3VLAgent] = None


def get_qwen3_vl_agent() -> Qwen3VLAgent:
    """
    Factory function para obtener instancia singleton del vision agent.
    
    Returns:
        Qwen3VLAgent: Instancia singleton
    
    Example:
        >>> agent = get_qwen3_vl_agent()
        >>> response = agent.invoke_vision("Describe", image_path="img.jpg")
    """
    global _qwen3_vl_agent
    
    if _qwen3_vl_agent is None:
        _qwen3_vl_agent = Qwen3VLAgent()
    
    return _qwen3_vl_agent


if __name__ == "__main__":
    # Test b√°sico
    print("Qwen3-VL-4B Vision Agent - v2.16.1")
    print("="*60)
    
    agent = get_qwen3_vl_agent()
    print(f"‚úÖ Agent creado: {agent.config.repo_id}")
    print(f"üìä RAM: {agent.config.memory_mb} MB")
    print(f"üîß Context: {agent.config.n_ctx} tokens")
    print(f"‚ö° Threads: {agent.config.n_threads}")
    print(f"üìå Permanente: {agent.config.permanent}")
