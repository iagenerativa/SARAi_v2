# GuÃ­a de CuantizaciÃ³n INT8 para agi_audio_core.onnx

## ğŸ¯ Â¿Por quÃ© INT8?

### AnÃ¡lisis Comparativo de Opciones

| CuantizaciÃ³n | TamaÃ±o | Velocidad CPU | PrecisiÃ³n | RAM | Hardware |
|--------------|--------|---------------|-----------|-----|----------|
| **FP32 (actual)** | 4.3 GB | 1x (7s) | 100% | 4.3 GB | Cualquier CPU |
| **FP16** | 2.15 GB | 1.5-2x | 99.5% | 2.2 GB | âŒ Requiere F16C/AVX512 |
| **INT8** | 1.1 GB | **3-4x (2s)** | 98-99% | 1.2 GB | âœ… Cualquier CPU |
| **INT4** | 550 MB | 4-6x | 95-97% | 600 MB | âš ï¸ Degrada audio |

### ğŸ† DecisiÃ³n: INT8 Dynamic Quantization

**Razones tÃ©cnicas:**

1. **Velocidad**: 3-4x mÃ¡s rÃ¡pido â†’ latencia 7s â†’ **~2s** âœ…
2. **RAM**: 4.3GB â†’ 1.2GB (**-72%**) â†’ Libera 3.1GB para otros modelos âœ…
3. **Calidad**: 98-99% precisiÃ³n â†’ imperceptible en audio âœ…
4. **Portabilidad**: Funciona en cualquier CPU x86-64 (no requiere extensiones) âœ…
5. **ONNX nativo**: Soporte completo en onnxruntime sin dependencias extra âœ…

**Por quÃ© NO otras opciones:**

- âŒ **FP16**: Requiere CPU moderno con F16C (Haswell+), no universal
- âŒ **INT4**: PÃ©rdida de calidad significativa (WER +5%, MOS -0.3 en audio)
- âŒ **Mixed precision**: Complejidad innecesaria para este caso de uso

---

## ğŸ“Š Impacto en KPIs v2.16.1

### RAM Profile (Antes vs DespuÃ©s)

```
ANTES (FP32):
BASELINE:  4.5 GB  (Audio 4.3GB + overhead 200MB)
PEAK:      8.8 GB  (+ LFM2 700MB + NLLB 600MB + Qwen3-VL 3.3GB)
FREE:      7.2 GB  (45% libre)

DESPUÃ‰S (INT8):
BASELINE:  1.4 GB  (Audio 1.2GB + overhead 200MB)  âœ… -69%
PEAK:      5.7 GB  (+ LFM2 700MB + NLLB 600MB + Qwen3-VL 3.3GB)  âœ… -35%
FREE:     10.3 GB  (64% libre)  âœ… +19pp
```

### Latencia Pipeline (Esperada)

```
AUDIO PROCESSING (INT8):
- Audio â†’ Codes:     <100ms  (sin cambios)
- ONNX Inference:    ~2.0s   (vs 7s FP32, -71%)  ğŸš€
- Post-processing:   <50ms   (sin cambios)
TOTAL E2E:           ~2.2s   (vs 7.2s, -69%)  âœ…

Con warmup + cache:
- Primera query:     2.2s    (warmup incluido)
- Segunda+ (cache):  0ms     (100% cache hit)  ğŸš€
```

### Throughput Real-Time

```
ANTES (FP32):
- Audio 1s: 7.0s procesamiento â†’ 0.14x real-time  âŒ
- Audio 3s: 6.9s procesamiento â†’ 0.43x real-time  âŒ

DESPUÃ‰S (INT8):
- Audio 1s: ~2.0s procesamiento â†’ 0.5x real-time   âš ï¸ (mejor pero aÃºn sub-RT)
- Audio 3s: ~2.0s procesamiento â†’ 1.5x real-time   âœ… (faster-than-realtime)
```

**Nota**: Para audio corto (<2s), seguirÃ¡ siendo sub-realtime. Para audio >2s, serÃ¡ faster-than-realtime.

---

## ğŸ”§ Proceso de CuantizaciÃ³n

### MÃ©todo: Dynamic Quantization

**QuÃ© es:**
- **Pesos (weights)**: FP32 â†’ INT8 (conversiÃ³n offline)
- **Activaciones**: FP32 en runtime â†’ INT8 dinÃ¡micamente
- **ComputaciÃ³n**: INT8 matrix multiplications (3-4x mÃ¡s rÃ¡pido)

**Por quÃ© Dynamic vs Static:**
- âœ… No requiere dataset de calibraciÃ³n
- âœ… MÃ¡s robusto a variaciones de audio
- âœ… Mejor precision/speed tradeoff para audio
- âœ… Menos complejidad de implementaciÃ³n

### Optimizaciones Aplicadas

```python
quantize_dynamic(
    model_input=input_model,
    model_output=output_model,
    weight_type=QuantType.QInt8,
    
    # Optimizaciones crÃ­ticas
    optimize_model=True,              # Graph optimization
    use_external_data_format=True,   # Mantiene .data separado
    
    extra_options={
        'EnableSubgraph': True,        # Optimiza subgrafos
        'ForceQuantizeNoInputCheck': False,  # MÃ¡s seguro
        'MatMulConstBOnly': False,     # Cuantiza ambos lados
    }
)
```

---

## ğŸš€ EjecuciÃ³n

### Paso 1: Cuantizar Modelo

```bash
# Desde raÃ­z del proyecto
python3 scripts/quantize_onnx_int8.py

# Confirmar cuando pregunte (y)
# Tiempo esperado: 5-10 minutos
```

**Output esperado:**

```
ğŸ”„ CuantizaciÃ³n INT8 Dynamic
============================================================
Input:  models/onnx/agi_audio_core.onnx
Output: models/onnx/agi_audio_core_int8.onnx

ğŸ“Š Modelo original: 4.25 GB

ğŸ”„ Iniciando cuantizaciÃ³n (puede tardar 5-10 min)...
   Procesando: FP32 â†’ INT8...

âœ… CuantizaciÃ³n completada en 347.2s
ğŸ“Š Modelo cuantizado: 7,842 bytes
ğŸ“Š Datos cuantizados: 1.08 GB
ğŸ¯ ReducciÃ³n de tamaÃ±o: 74.6%

âœ… Modelo guardado en: models/onnx/agi_audio_core_int8.onnx
```

### Paso 2: Actualizar ConfiguraciÃ³n

```bash
# Editar config/sarai.yaml
vim config/sarai.yaml
```

**Cambios en `audio_omni` section:**

```yaml
audio_omni:
  name: "Qwen3-Omni-3B-INT8"  # Cambiar nombre
  model_type: "onnx"
  model_path: "models/onnx/agi_audio_core_int8.onnx"  # Cambiar path
  backend: "onnxruntime"
  max_memory_mb: 1200  # Cambiar de 4400 a 1200
  permanent: true
  load_on_startup: true
  priority: "high"
```

### Paso 3: Actualizar Pipeline

```bash
# Editar agents/audio_omni_pipeline.py
vim agents/audio_omni_pipeline.py
```

**Cambios en `AudioOmniConfig.__init__`:**

```python
def __init__(self):
    self.model_path: str = "models/onnx/agi_audio_core_int8.onnx"  # Cambiar
    self.model_type: str = "onnx"
    self.backend: str = "onnxruntime"
    self.max_memory_mb: int = 1200  # Cambiar de 4400
    self.sample_rate: int = 22050
    self.n_threads: int = 4
```

### Paso 4: Validar con Tests

```bash
# Ejecutar suite de tests
python3 scripts/test_onnx_pipeline.py
```

**Resultados esperados:**

```
ğŸ§ª Test 2: Inferencia ONNX...
âœ… Inferencia exitosa en 2.1s  â† vs 7s anterior (-70%)

ğŸ“Š Benchmark de performance...
   0.5s audio: 2.3s latencia  â† vs 7.3s (-68%)
   1.0s audio: 0.0s latencia  â† cache hit
   2.0s audio: 2.1s latencia  â† vs 7.0s (-70%)
   3.0s audio: 2.0s latencia  â† vs 6.9s (-71%)

ğŸ¯ MÃ©tricas finales:
   Latencia promedio: 1.6s  â† vs 5.3s (-70%)
   âœ… Latencia objetivo alcanzado (<2s)
```

---

## ğŸ§ª ValidaciÃ³n de Calidad

### MÃ©tricas a Verificar

| MÃ©trica | FP32 (baseline) | INT8 (esperado) | Delta Aceptable |
|---------|-----------------|-----------------|-----------------|
| **STT WER** | 2.0% | 2.2% | â‰¤0.5pp âœ… |
| **TTS MOS** | 4.21 | 4.15 | â‰¥4.0 âœ… |
| **Emotion Accuracy** | 87% | 85% | â‰¥80% âœ… |
| **Latency P50** | 7.0s | 2.0s | â‰¤2.5s âœ… |
| **RAM P99** | 4.3GB | 1.2GB | â‰¤1.5GB âœ… |

### Tests de RegresiÃ³n

```bash
# Test 1: Audio limpio (sine wave)
python3 scripts/test_onnx_pipeline.py

# Test 2: Audio con ruido
# TODO: Crear dataset de test con ruido ambiente

# Test 3: MÃºltiples idiomas
# TODO: Validar espaÃ±ol, inglÃ©s si el modelo soporta
```

---

## ğŸ“ Rollback Plan

Si la cuantizaciÃ³n degrada calidad inaceptablemente:

### OpciÃ³n 1: Volver a FP32

```yaml
# config/sarai.yaml
audio_omni:
  model_path: "models/onnx/agi_audio_core.onnx"  # Modelo original
  max_memory_mb: 4400
```

### OpciÃ³n 2: Probar FP16 (si CPU soporta)

```bash
# Verificar soporte F16C
grep f16c /proc/cpuinfo

# Si existe, probar FP16
python3 scripts/quantize_onnx_fp16.py  # TODO: crear script
```

### OpciÃ³n 3: Mixed Precision (hÃ­brido)

Cuantizar solo capas pesadas, mantener crÃ­ticas en FP32.

---

## ğŸ¯ Impacto en Arquitectura v2.16.1

### Antes (FP32):

```
Audio ONNX FP32:    4.3 GB  (permanente)
LFM2-1.2B:          0.7 GB  (consolidado)
SOLAR HTTP:         0.2 GB  (local)
EmbeddingGemma:     0.15 GB (permanente)
TRM-Router:         0.05 GB (permanente)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
BASELINE:           5.4 GB  (66% RAM libre)
PEAK (+ Vision):    8.7 GB  (46% RAM libre)
```

### DespuÃ©s (INT8):

```
Audio ONNX INT8:    1.2 GB  (permanente)  âœ… -3.1GB
LFM2-1.2B:          0.7 GB  (consolidado)
SOLAR HTTP:         0.2 GB  (local)
EmbeddingGemma:     0.15 GB (permanente)
TRM-Router:         0.05 GB (permanente)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
BASELINE:           2.3 GB  (86% RAM libre)  âœ… +20pp
PEAK (+ Vision):    5.6 GB  (65% RAM libre)  âœ… +19pp
```

**Beneficio clave**: Libera 3.1GB para:
- Cargar mÃ¡s modelos simultÃ¡neamente
- Reducir swapping en sistemas con 8GB RAM
- Mejorar rendimiento de cache CPU

---

## ğŸ”’ Consideraciones de Seguridad

### VerificaciÃ³n de Integridad

```bash
# DespuÃ©s de cuantizaciÃ³n, verificar checksum
sha256sum models/onnx/agi_audio_core_int8.onnx
sha256sum models/onnx/agi_audio_core_int8.onnx.data

# Guardar en registro
echo "SHA-256: $(sha256sum models/onnx/agi_audio_core_int8.onnx.data)" >> \
  models/onnx/CHECKSUMS.txt
```

### AuditorÃ­a

```bash
# Registrar versiÃ³n de herramientas
python3 -c "import onnx; print(f'onnx: {onnx.__version__}')" >> \
  state/quantization_log.txt

python3 -c "import onnxruntime; print(f'onnxruntime: {onnxruntime.__version__}')" >> \
  state/quantization_log.txt

# Registrar timestamp y usuario
echo "Cuantizado: $(date -u +%Y-%m-%dT%H:%M:%SZ) por $(whoami)" >> \
  state/quantization_log.txt
```

---

## ğŸ“š Referencias

- **ONNX Quantization**: https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html
- **Dynamic vs Static**: https://github.com/microsoft/onnxruntime/blob/main/docs/Quantization.md
- **INT8 Performance**: https://arxiv.org/abs/1806.08342 (Integer Quantization for DNNs)
- **Audio Quality**: WER/MOS preservation en modelos cuantizados

---

**Estado**: â³ PENDIENTE DE EJECUCIÃ“N  
**PrÃ³ximo**: Ejecutar `python3 scripts/quantize_onnx_int8.py` y confirmar  
**Tiempo estimado**: 5-10 minutos cuantizaciÃ³n + 2 minutos validaciÃ³n  
**Beneficio esperado**: -70% latencia, -72% RAM
