# üé§ Testing Interactivo con Micr√≥fono

## Descripci√≥n

SARAi v2.11 incluye tests interactivos que permiten validar la detecci√≥n de idioma y emociones usando tu **micr√≥fono real**.

## üìã Requisitos

### Dependencias Python

```bash
pip install pyaudio scipy
```

### Hardware

- Micr√≥fono funcional
- Permisos de acceso al micr√≥fono (Linux: verificar con `arecord -l`)

## üöÄ Uso R√°pido

### Opci√≥n 1: Script Helper (RECOMENDADO)

```bash
# Test de detecci√≥n de idioma
python scripts/test_microphone.py --audio-router

# Test de detecci√≥n emocional
python scripts/test_microphone.py --emotion

# Ambos tests
python scripts/test_microphone.py --all
```

### Opci√≥n 2: Pytest Directo

```bash
# Test de idioma
pytest tests/test_audio_router.py::TestLanguageDetector::test_detect_with_real_microphone -s

# Test de emoci√≥n
pytest tests/test_emotion_modulator.py::TestEmotionModulationIntegration::test_emotion_detection_with_real_microphone -s

# Ambos (filtro por keyword)
pytest tests/ -k real_microphone -s
```

## üìñ Gu√≠a de Tests

### Test 1: Detecci√≥n de Idioma üåç

**Objetivo**: Validar que el `LanguageDetector` identifica correctamente el idioma hablado.

**Proceso**:
1. El sistema grabar√° **5 segundos** de audio
2. Habla en cualquier idioma (espa√±ol, ingl√©s, franc√©s, etc.)
3. El sistema mostrar√° el idioma detectado
4. Confirma si es correcto (y/n)

**Idiomas Soportados**:
- üá™üá∏ Espa√±ol (es)
- üá¨üáß English (en)
- üá´üá∑ Fran√ßais (fr)
- üá©üá™ Deutsch (de)
- üáØüáµ Êó•Êú¨Ë™û (ja)
- üáµüáπ Portugu√™s (pt)
- üáÆüáπ Italiano (it)
- üá∑üá∫ –†—É—Å—Å–∫–∏–π (ru)
- üá®üá≥ ‰∏≠Êñá (zh)
- üá∏üá¶ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© (ar)
- üáÆüá≥ ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä (hi)
- üá∞üá∑ ÌïúÍµ≠Ïñ¥ (ko)

**Ejemplo de Output**:

```
üé§ TEST INTERACTIVO: Detecci√≥n de idioma con micr√≥fono
================================================================

üìã Configuraci√≥n:
   - Duraci√≥n: 5 segundos
   - Sample rate: 16000 Hz
   - Channels: 1

‚ñ∂Ô∏è  Presiona ENTER para comenzar a grabar...

üî¥ GRABANDO... (habla en cualquier idioma)
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚úÖ Grabaci√≥n completada

üîç Detectando idioma...

================================================================
‚úÖ RESULTADO: EN
================================================================

üåç Idioma detectado: English (en)

‚ùì ¬øEs correcto? (y/n): y
‚úÖ Test PASSED - Detecci√≥n correcta
```

### Test 2: Detecci√≥n Emocional üé≠

**Objetivo**: Validar que el `EmotionModulator` identifica correctamente el estado emocional del hablante.

**Proceso**:
1. El sistema grabar√° **3 segundos** de audio
2. Expresa una emoci√≥n clara (alegr√≠a, tristeza, enojo, etc.)
3. El sistema analizar√° las caracter√≠sticas ac√∫sticas
4. Mostrar√° la emoci√≥n detectada + scores + features
5. Confirma si es correcto (y/n)

**Emociones Detectables**:
- üòä HAPPY (feliz, alegre)
- üò¢ SAD (triste, deprimido)
- üò† ANGRY (enojado, furioso)
- üò® FEARFUL (miedo, nervioso)
- üòÆ SURPRISED (sorprendido)
- ü§¢ DISGUSTED (asco)
- üòå CALM (tranquilo, sereno)
- ü§© EXCITED (emocionado, excitado)
- üòê NEUTRAL (neutro)

**Ejemplos de Frases**:

```python
# Feliz
"¬°Estoy muy contento hoy! Todo va genial"

# Triste
"Me siento mal... esto me deprime"

# Enojado
"¬°Esto es frustrante! ¬°No puede ser!"

# Tranquilo
"Todo est√° bien, estoy relajado"
```

**Ejemplo de Output**:

```
üé≠ TEST INTERACTIVO: Detecci√≥n de emoci√≥n con micr√≥fono
======================================================================

üìã Instrucciones:
   1. Grabar√°s 3 segundos de audio
   2. Expresa una emoci√≥n clara (alegr√≠a, tristeza, enojo, etc.)
   3. El sistema detectar√° tu estado emocional

‚ñ∂Ô∏è  Presiona ENTER cuando est√©s listo...

üî¥ GRABANDO... (expresa una emoci√≥n)
   üí° Ejemplos:
      - Feliz: 'Estoy muy contento hoy!'
      - Triste: 'Me siento mal...'
      - Enojado: '¬°Esto es frustrante!'
      - Tranquilo: 'Todo est√° bien'

‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚úÖ Grabaci√≥n completada

üîç Analizando emoci√≥n del audio...

======================================================================
üìä RESULTADOS DE AN√ÅLISIS EMOCIONAL
======================================================================

üé≠ Emoci√≥n Primaria: üòä HAPPY
   Intensidad: 0.78 / 1.00
   Confianza: 0.65 / 1.00

üìà Top 3 Scores:
   1. happy        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.520
   2. excited      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.280
   3. neutral      ‚ñà‚ñà‚ñà‚ñà 0.200

üîä Caracter√≠sticas Ac√∫sticas:
   Energ√≠a promedio: 0.3245
   Energ√≠a m√°xima: 0.8912
   Desviaci√≥n std: 0.2134
   Zero-crossing rate: 0.0876

======================================================================
‚ùì ¬øLa detecci√≥n es correcta? (y/n): y

‚úÖ Test PASSED - Detecci√≥n emocional correcta
   Emoci√≥n detectada: happy
   Confianza: 65.0%
```

## üêõ Troubleshooting

### Error: "No module named 'pyaudio'"

```bash
# Ubuntu/Debian
sudo apt-get install portaudio19-dev python3-pyaudio
pip install pyaudio

# macOS
brew install portaudio
pip install pyaudio

# Fedora/RHEL
sudo dnf install portaudio-devel
pip install pyaudio
```

### Error: "ALSA lib ... cannot open shared library"

```bash
# Linux: Verificar permisos de audio
groups $USER  # Debe incluir 'audio'

# Si no est√°:
sudo usermod -a -G audio $USER
# Logout y login de nuevo
```

### Error: "Input overflowed"

Esto es normal si el buffer del micr√≥fono se llena. El test continuar√° correctamente.

### Micr√≥fono no detectado

```bash
# Listar dispositivos de audio
arecord -l

# Probar grabaci√≥n manual
arecord -d 3 -f cd test.wav
aplay test.wav
```

## üìä Interpretaci√≥n de Resultados

### Detecci√≥n de Idioma

**Confianza alta** (>0.8): El modelo est√° muy seguro del idioma detectado
**Confianza media** (0.5-0.8): Detecci√≥n correcta pero con incertidumbre
**Confianza baja** (<0.5): Puede ser necesario m√°s audio o contexto

### Detecci√≥n Emocional

**Fase 1 (Actual)**: Heur√≠sticas b√°sicas
- Precisi√≥n esperada: ~60-70%
- Basado en energ√≠a, ZCR, keywords

**Fase 2 (Pr√≥ximo)**: Modelo pre-entrenado (emoDBert)
- Precisi√≥n objetivo: ‚â•85%
- MOS Empat√≠a: ‚â•4.0/5.0

### Caracter√≠sticas Ac√∫sticas

| Feature | Rango | Interpretaci√≥n |
|---------|-------|----------------|
| Energ√≠a promedio | 0.0-1.0 | Volumen general (alto = excited/angry) |
| Energ√≠a m√°xima | 0.0-1.0 | Picos de volumen (alto = √©nfasis) |
| Desviaci√≥n std | 0.0-0.5 | Variabilidad (alto = angry/fearful) |
| ZCR | 0.0-0.3 | Pitch/excitaci√≥n (alto = excited) |

## üéØ Casos de Uso

### Desarrollo

```bash
# Validar cambios en LanguageDetector
python scripts/test_microphone.py --audio-router

# Validar cambios en EmotionModulator
python scripts/test_microphone.py --emotion
```

### Testing de Regresi√≥n

```bash
# Ejecutar ambos tests antes de merge
python scripts/test_microphone.py --all
```

### Demostraci√≥n

```bash
# Demo para stakeholders
python scripts/test_microphone.py --all
```

## üìö Referencias

- **Whisper**: https://github.com/openai/whisper
- **fastText LID**: https://fasttext.cc/docs/en/language-identification.html
- **Emotion Detection**: Ekman, P. (1992). "An argument for basic emotions"

## üîó Archivos Relacionados

- `tests/test_audio_router.py`: Test de detecci√≥n de idioma
- `tests/test_emotion_modulator.py`: Test de detecci√≥n emocional
- `agents/audio_router.py`: Implementaci√≥n LanguageDetector
- `agents/emotion_modulator.py`: Implementaci√≥n EmotionModulator
- `scripts/test_microphone.py`: Script helper

---

**Autor**: SARAi Team  
**Versi√≥n**: v2.11  
**Fecha**: 2025-10-28
