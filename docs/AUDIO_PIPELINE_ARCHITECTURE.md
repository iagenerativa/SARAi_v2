# Arquitectura del Pipeline de Audio v2.16.3

## ğŸ¯ Objetivo

Crear un pipeline **modular y eficiente** para procesamiento de voz que use **LFM2 como cerebro** en lugar de modelos externos de 7GB.

---

## ğŸ“Š Comparativa de Arquitecturas

### âŒ Arquitectura Incorrecta (Qwen2.5-Omni-7B MonolÃ­tico)

```
Audio Input (WAV)
  â†“
Qwen2.5-Omni-7B (7GB)
  â”œâ”€ Audio Encoder (3.5GB)
  â”œâ”€ Language Model (7B params)
  â”œâ”€ Talker (integrado)
  â””â”€ Vocoder BigVGAN (1.2GB)
  â†“
Audio Output / Text

Total RAM: ~12GB
Problema: Usa modelo LLM de 7B cuando ya tenemos LFM2-1.2B
```

---

## âœ… Arquitectura Correcta (Modular con LFM2 - IMPLEMENTABLE)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PIPELINE DE VOZ COMPLETO - ONNX PURO               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Flujo 1: AUDIO â†’ TEXTO (STT - Speech-to-Text)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. ğŸ¤ Audio Input (WAV 16kHz)
   â†“
2. ğŸ§ Audio Encoder (qwen25_audio_int8.onnx ~97MB)
   â†’ Convierte audio â†’ audio_features [B, T, D]
   â†’ Latencia: ~100ms
   â†“
3. ğŸ“ Audio Decoder (qwen25_audio_int8.onnx ~97MB) â† REUTILIZADO
   â†’ Audio features â†’ Texto
   â†’ Latencia: ~40ms
   â†“
   ğŸ“„ TEXTO TRANSCRITO


Flujo 2: TEXTO â†’ RAZONAMIENTO (LLM)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

4. ğŸ§  Thinker (LFM2-1.2B GGUF ~700MB)
   â†’ Texto entrada â†’ Razonamiento â†’ Texto respuesta
   â†’ Latencia: ~200-400ms (segÃºn longitud)
   â†“
   ğŸ“„ TEXTO RESPUESTA


Flujo 3: TEXTO â†’ AUDIO (TTS - Text-to-Speech)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

5. ğŸ—£ï¸ Text Encoder (qwen25_audio_int8.onnx ~97MB) â† REUTILIZADO
   â†’ Texto â†’ hidden_states [B, S, 3584]
   â†’ Latencia: ~40ms
   â†“
6. âœ… Talker (qwen25_7b_audio.onnx ~41MB) â† COMPONENTE ESPECÃFICO
   â†’ hidden_states â†’ audio_logits [B, S, 8448]
   â†’ Latencia: ~5ms âš¡
   â†“
7. ğŸ”Š Vocoder (qwen25_audio_int8.onnx ~97MB) â† REUTILIZADO
   â†’ audio_logits â†’ waveform de audio
   â†’ Latencia: ~100ms
   â†“
   ğŸµ AUDIO OUTPUT
```

**Total RAM**: ~840MB (qwen25_audio_int8.onnx compartido ~97MB + Talker 42MB + LFM2 700MB)
**Latencia E2E**: ~485ms (STT 140ms + LFM2 250ms + TTS 145ms)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PIPELINE DE VOZ COMPLETO - ONNX PURO               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Flujo 1: AUDIO â†’ TEXTO (STT - Speech-to-Text)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. ğŸ¤ Audio Input (WAV 16kHz)
   â†“
2. ğŸ§ Audio Encoder (qwen25_audio_int8.onnx ~97MB)
   â†’ Convierte audio â†’ audio_features [B, T, D]
   â†’ Latencia: ~100ms
   â†“
   ï¿½ AUDIO FEATURES


Flujo 2: TEXTO â†’ RAZONAMIENTO (LLM)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

3. ğŸ§  Thinker (LFM2-1.2B GGUF ~700MB)
   â†’ Audio features â†’ Texto razonado
   â†’ Latencia: ~200-400ms (segÃºn longitud)
   â†“
   ğŸ“„ TEXTO RESPUESTA


Flujo 3: TEXTO â†’ AUDIO (TTS - Text-to-Speech)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

4. ğŸ—£ï¸ Text-to-Features
   â†’ Texto â†’ hidden_states [B, S, 3584]
   â†’ Latencia: ~40ms
   â†“
5. âœ… Talker (qwen25_7b_audio.onnx ~41MB) â† EL QUE TENEMOS
   â†’ hidden_states â†’ audio_logits [B, S, 8448]
   â†’ Latencia: ~5ms âš¡
   â†“
6. ğŸ”Š Vocoder (qwen25_audio_int8.onnx ~97MB) â† REUTILIZADO
   â†’ audio_logits â†’ waveform de audio
   â†’ Latencia: ~100ms
   â†“
   ğŸµ AUDIO OUTPUT
```

**Total RAM**: ~935MB (encoder/vocoder comparten modelo, ~97MB cargado 1 vez)
**Latencia E2E**: ~445ms (STT 100ms + LFM2 250ms + TTS 145ms)

---

## ğŸ”§ Componentes Necesarios

### âœ… Ya Tenemos (IMPLEMENTABLE HOY)

1. **Audio Encoder/Decoder**: `models/onnx/qwen25_audio_int8.onnx` (~97MB) âœ…
   - **UbicaciÃ³n**: `models/onnx/qwen25_audio_int8.onnx` (97 MB archivo Ãºnico)
   - **CuantizaciÃ³n**: INT8 optimizado para CPU
   - FunciÃ³n Quad: 
     - STT Encoder: Audio â†’ Features
     - STT Decoder: Features â†’ Texto
     - TTS Encoder: Texto â†’ Features
     - TTS Vocoder: Audio logits â†’ Waveform
   - Compatible con formato ONNX nativo

2. **Talker**: `models/onnx/qwen25_7b_audio.onnx` + `.data` (~42MB) âœ…
   - **UbicaciÃ³n**:
     - Header: `models/onnx/qwen25_7b_audio.onnx` (922 bytes)
     - Data: `models/onnx/qwen25_7b_audio.onnx.data` (41.2 MB)
   - Input: hidden_states [B, S, 3584]
   - Output: audio_logits [B, S, 8448]
   - Modelo ONNX especÃ­fico para TTS

3. **Thinker (LLM)**: LFM2-1.2B GGUF (~700MB) âœ…
   - Razonamiento: Texto entrada â†’ Texto respuesta
   - Formato: GGUF (llama.cpp)
   - Acceso: ModelPool.get("tiny")

**Total modelos Ãºnicos**: 2 ONNX (139MB) + 1 GGUF (700MB) = **~840MB**

**ComparticiÃ³n de memoria**:
- qwen25_audio_int8.onnx se carga UNA VEZ (97MB), se usa en CUATRO puntos:
  1. Audio â†’ Features (Encoder STT)
  2. Features â†’ Texto (Decoder STT)
  3. Texto â†’ Features (Encoder TTS)
  4. Audio logits â†’ Waveform (Vocoder TTS)
- Esto ahorra ~291MB vs cargar 4 modelos separados (97MB Ã— 4 = 388MB)

### â³ CANCELADO - Ya no necesitamos exportar nada

~~| Componente | Modelo Base | Exportar a ONNX | TamaÃ±o Estimado |~~  
~~|------------|-------------|-----------------|-----------------|~~  
~~| Audio Encoder | Whisper-tiny | whisper_encoder.onnx | ~39MB |~~  
~~| Vocoder | BigVGAN | bigvgan_vocoder.onnx | ~150MB |~~  
~~| TTS Encoder | Qwen2.5-Omni | tts_text_encoder.onnx | ~200MB |~~

**âœ… Ventaja clave**: `qwen25_audio_int8.onnx` sirve TANTO para encoder como vocoder

---

## ğŸ“ Pipeline E2E Actual (Implementado)

### Flujo Simplificado: Audio â†’ Texto â†’ LFM2

```python
# PASO 1: Audio â†’ Texto (STT)
# Usamos modelo TEMPORAL monolÃ­tico mientras exportamos Whisper
audio_bytes = load_audio("input.wav")
text = whisper_stt(audio_bytes)  # TODO: Reemplazar con whisper_encoder.onnx

# PASO 2: Texto â†’ Razonamiento (LFM2)
model_pool = ModelPool("config/sarai.yaml")
lfm2 = model_pool.get("tiny")  # LFM2-1.2B GGUF
response = lfm2(f"Usuario: {text}\nAsistente:")

# PASO 3: Respuesta en texto
print(response)
```

**RAM Total**: ~1.5GB (Whisper 39MB + LFM2 700MB + overhead)  
**Latencia E2E**: ~350ms (Whisper 80ms + LFM2 250ms)

---

## ğŸš€ Pipeline Completo Futuro: Voz â†’ Voz

```python
# PASO 1: Audio â†’ Texto (STT)
audio_encoder = load_onnx("whisper_encoder.onnx")  # 39MB
embeddings = audio_encoder(audio_bytes)
text = decode_text(embeddings)

# PASO 2: Texto â†’ Razonamiento (LFM2)
lfm2 = model_pool.get("tiny")
response_text = lfm2(f"Usuario: {text}\nAsistente:")

# PASO 3: Texto â†’ Audio (TTS)
tts_encoder = load_onnx("tts_text_encoder.onnx")  # 200MB
hidden_states = tts_encoder(response_text)

talker = load_onnx("qwen25_7b_audio.onnx")  # 41MB âœ…
audio_logits = talker(hidden_states)

vocoder = load_onnx("bigvgan_vocoder.onnx")  # 150MB
audio_output = vocoder(audio_logits)

# PASO 4: Reproducir audio
play_audio(audio_output)
```

**RAM Total**: ~1.3GB (Whisper 39MB + LFM2 700MB + Talker 41MB + Vocoder 150MB + TTS Encoder 200MB + overhead)  
**Latencia E2E**: ~450ms (STT 80ms + LFM2 250ms + TTS 120ms)

---

## ğŸ“¦ Scripts de ExportaciÃ³n Necesarios

### 1. Exportar Whisper Encoder

```bash
python scripts/export_whisper_encoder.py \
  --model openai/whisper-tiny \
  --output models/onnx/whisper_encoder.onnx \
  --optimize int8
```

### 2. Exportar Vocoder BigVGAN

```bash
python scripts/export_bigvgan_vocoder.py \
  --model nvidia/bigvgan \
  --output models/onnx/bigvgan_vocoder.onnx \
  --optimize fp16
```

### 3. Exportar TTS Text Encoder

```bash
python scripts/export_tts_encoder.py \
  --model Qwen/Qwen2.5-Omni-7B \
  --component text_encoder \
  --output models/onnx/tts_text_encoder.onnx \
  --optimize int8
```

---

## âœ… PrÃ³ximos Pasos

1. **Inmediato**: Usar modelo monolÃ­tico para STT mientras exportamos Whisper
2. **Corto plazo** (esta semana):
   - Exportar Whisper-tiny a ONNX
   - Exportar BigVGAN a ONNX
   - Exportar TTS Text Encoder a ONNX
3. **Medio plazo** (prÃ³xima semana):
   - Integrar componentes ONNX en AudioOmniPipeline
   - Validar latencia E2E <500ms
   - Documentar benchmarks

---

## ğŸ¯ KPIs del Pipeline Modular Final

| MÃ©trica | Objetivo | Estado |
|---------|----------|--------|
| RAM P99 | â‰¤ 2GB | â³ Pendiente validar |
| Latencia STT | â‰¤ 100ms | â³ Pendiente exportar Whisper |
| Latencia LFM2 | â‰¤ 300ms | âœ… Ya funciona |
| Latencia TTS | â‰¤ 150ms | â³ Pendiente exportar componentes |
| **Latencia E2E** | **â‰¤ 500ms** | **â³ Objetivo** |
| Calidad MOS | â‰¥ 4.0 | â³ Pendiente evaluar |

---

## ğŸ”’ Sin Dependencias de Qwen2.5-Omni-7B

**Clave**: El Talker ONNX (41MB) es **solo una pieza**. NO contiene Encoder ni Vocoder integrados.

- âŒ **NO** cargar Qwen2.5-Omni-7B completo (7GB)
- âœ… **SÃ** usar componentes ONNX independientes (~430MB total)
- âœ… **SÃ** usar LFM2-1.2B como cerebro (700MB)

**Ahorro de RAM**: 7GB â†’ 1.3GB (reducciÃ³n del 81%)
