# üéØ Modelos Especializados - Implementaci√≥n v2.14

**Fecha**: 2025-11-01  
**Estrategia**: Especializaci√≥n por nicho con routing inteligente  
**Filosof√≠a**: Skills como prompts + Modelos especializados para nichos cr√≠ticos

---

## üß† Planteamiento Validado

### Uso Estrat√©gico de Modelos Especializados

**Tu criterio** (validado y aprobado):

1. **LLaMarketing-8B**: Para solicitudes **muy espec√≠ficas de marketing** (no gen√©ricas)
   - Copy publicitario avanzado
   - Campa√±as multi-canal
   - SEO t√©cnico
   - **NO para**: "Escribe un email" o "Crea un tweet"

2. **Qwen2.5-Coder-7B**: Para **tareas avanzadas de desarrollo** (no b√°sicas)
   - Arquitectura de sistemas complejos
   - Debugging profundo
   - Code review t√©cnico
   - **NO para**: "¬øQu√© es Python?" o "Explica loops"

3. **SOLAR-10.7B**: Para **todo lo dem√°s** (general purpose)
   - Preguntas gen√©ricas
   - Razonamiento general
   - Explicaciones t√©cnicas b√°sicas

---

## üìã Sistema de Routing Inteligente

### Nivel 1: TRM-Router (Clasificaci√≥n Base)

```python
# core/trm_classifier.py
scores = trm_router.invoke(user_input)
# {
#   "hard": 0.85,
#   "soft": 0.15,
#   "programming": 0.9,   # Skill detectado
#   "marketing": 0.1
# }
```

### Nivel 2: Skill Detection (Long-tail Matching)

```python
# core/skill_configs.py
def detect_specialized_skill(query: str, scores: dict) -> Optional[str]:
    """
    Detecta si la query requiere modelo especializado
    
    Returns:
        - "qwen_coder": Qwen2.5-Coder-7B (dev avanzado)
        - "llamarketing": LLaMarketing-8B (marketing nicho)
        - None: Usar SOLAR (gen√©rico)
    """
    
    # CRITERIO 1: Qwen2.5-Coder (desarrollo avanzado)
    # Solo si: skill=programming Y complejidad alta
    if scores.get("programming", 0) > 0.7:
        # Keywords de complejidad avanzada
        advanced_dev_keywords = [
            # Arquitectura
            ("arquitectura", "microservicios", 3.0),
            ("dise√±o", "sistema", 2.5),
            ("patrones", "dise√±o", 2.5),
            
            # Debugging profundo
            ("debug", "segfault", 3.0),
            ("memory", "leak", 3.0),
            ("profiling", "performance", 2.5),
            
            # Code review t√©cnico
            ("refactor", "c√≥digo", 2.5),
            ("optimizaci√≥n", "algoritmo", 3.0),
            ("complejidad", "temporal", 2.5),
        ]
        
        for word1, word2, weight in advanced_dev_keywords:
            if word1 in query.lower() and word2 in query.lower():
                if weight >= 2.5:
                    return "qwen_coder"
    
    # CRITERIO 2: LLaMarketing (marketing nicho)
    # Solo si: keywords muy espec√≠ficos de marketing
    marketing_niche_keywords = [
        # Copy avanzado
        ("copy", "publicitario", 3.0),
        ("anuncio", "conversi√≥n", 3.0),
        
        # Campa√±as multi-canal
        ("campa√±a", "omnicanal", 3.0),
        ("estrategia", "marketing", 2.5),
        
        # SEO t√©cnico
        ("seo", "t√©cnico", 3.0),
        ("keyword", "research", 2.5),
        
        # Funnel de ventas
        ("funnel", "ventas", 2.5),
        ("lead", "nurturing", 3.0),
    ]
    
    for word1, word2, weight in marketing_niche_keywords:
        if word1 in query.lower() and word2 in query.lower():
            if weight >= 2.5:
                return "llamarketing"
    
    # DEFAULT: SOLAR (gen√©rico)
    return None
```

### Nivel 3: MCP Routing (Selecci√≥n de Modelo)

```python
# core/mcp.py
def route_to_model(self, state: State) -> str:
    """
    Routing inteligente a modelo especializado o gen√©rico
    
    Prioridad:
      1. Especializaci√≥n nicho (Qwen/LLaMarketing)
      2. Gen√©rico competente (SOLAR)
      3. Tiny fallback (LFM2)
    """
    
    # Detectar skill especializado
    from core.skill_configs import detect_specialized_skill
    specialized = detect_specialized_skill(state["input"], state)
    
    if specialized == "qwen_coder":
        return "qwen25_coder_long"  # Desarrollo avanzado
    
    elif specialized == "llamarketing":
        return "llamarketing_long"  # Marketing nicho
    
    # DEFAULT: SOLAR (gen√©rico)
    elif state["hard"] > 0.7:
        context_len = len(state["input"])
        return "solar_long" if context_len > 400 else "solar_short"
    
    # Fallback: LFM2 (soft-skills)
    else:
        return "lfm2"
```

---

## üì¶ Configuraci√≥n models.yaml

### Modelos Especializados (NUEVOS)

```yaml
# ----------------------------------------------------------------------------
# MODELOS ESPECIALIZADOS - OLLAMA REMOTE
# ----------------------------------------------------------------------------

qwen25_coder_long:
  name: "Qwen2.5-Coder-7B-Instruct (Long Context)"
  type: "text"
  backend: "ollama"
  
  # Especializaci√≥n: Desarrollo avanzado, arquitectura, debugging
  # NO usar para: Preguntas b√°sicas de programaci√≥n
  # Routing: Solo si detect_specialized_skill() == "qwen_coder"
  
  api_url: "${OLLAMA_BASE_URL}"
  model_name: "${QWEN_CODER_MODEL_NAME}"
  
  # Contexto largo para an√°lisis de c√≥digo complejo
  n_ctx: 2048
  
  # Temperatura baja (determinista para c√≥digo)
  temperature: 0.3
  max_tokens: 1024
  top_p: 0.9
  
  # Gesti√≥n de memoria
  load_on_demand: true
  priority: 7  # Media-alta (especializado)
  max_memory_mb: 0  # Ollama remoto

llamarketing_long:
  name: "LLaMarketing-8B (Long Context)"
  type: "text"
  backend: "ollama"
  
  # Especializaci√≥n: Marketing nicho (copy, campa√±as, SEO t√©cnico)
  # NO usar para: Emails gen√©ricos, tweets simples
  # Routing: Solo si detect_specialized_skill() == "llamarketing"
  
  api_url: "${OLLAMA_BASE_URL}"
  model_name: "${LLAMARKETING_MODEL_NAME}"
  
  # Contexto largo para campa√±as multi-canal
  n_ctx: 2048
  
  # Temperatura alta (creatividad)
  temperature: 0.9
  max_tokens: 1024
  top_p: 0.95
  
  # Gesti√≥n de memoria
  load_on_demand: true
  priority: 6  # Media (nicho espec√≠fico)
  max_memory_mb: 0  # Ollama remoto
```

---

## üîß Variables .env

### Configuraci√≥n Completa

```bash
# ============================================================================
# MODELOS EXTERNOS - OLLAMA REMOTE
# ============================================================================

# Servidor Ollama
OLLAMA_BASE_URL=http://<OLLAMA_HOST>:11434

# Modelo gen√©rico (hard-skills general)
SOLAR_MODEL_NAME=una-solar-10.7b-instruct-v1.0-q4

# Modelo especializado: Desarrollo avanzado
# Uso: Arquitectura, debugging profundo, code review t√©cnico
# NO usar para: Preguntas b√°sicas de Python, "¬øQu√© es un loop?"
QWEN_CODER_MODEL_NAME=qwen2.5-coder:7b-instruct

# Modelo especializado: Marketing nicho
# Uso: Copy publicitario, campa√±as omnicanal, SEO t√©cnico
# NO usar para: Emails gen√©ricos, tweets simples
LLAMARKETING_MODEL_NAME=llamarketing:8b
```

---

## üìä Matriz de Decisi√≥n de Routing

### Ejemplos de Queries y Routing

| Query | Skill | Especializado? | Modelo | Raz√≥n |
|-------|-------|----------------|--------|-------|
| "¬øQu√© es Python?" | programming | ‚ùå NO | **solar_short** | Pregunta b√°sica ‚Üí gen√©rico |
| "Explica loops" | programming | ‚ùå NO | **solar_short** | Conceptos b√°sicos ‚Üí gen√©rico |
| "Arquitectura microservicios Docker" | programming | ‚úÖ S√ç | **qwen25_coder** | Keywords: arquitectura+microservicios (3.0) |
| "Debug segfault en C++" | programming | ‚úÖ S√ç | **qwen25_coder** | Keywords: debug+segfault (3.0) |
| "Optimizaci√≥n algoritmo O(n¬≤) ‚Üí O(n log n)" | programming | ‚úÖ S√ç | **qwen25_coder** | Keywords: optimizaci√≥n+algoritmo (3.0) |
| "Escribe un email profesional" | - | ‚ùå NO | **solar_short** | No es marketing nicho ‚Üí gen√©rico |
| "Crea un tweet sobre IA" | - | ‚ùå NO | **solar_short** | Social media simple ‚Üí gen√©rico |
| "Copy publicitario campa√±a multi-canal" | marketing | ‚úÖ S√ç | **llamarketing** | Keywords: copy+publicitario (3.0) |
| "Estrategia SEO t√©cnico schema markup" | marketing | ‚úÖ S√ç | **llamarketing** | Keywords: seo+t√©cnico (3.0) |
| "Funnel de ventas lead nurturing" | marketing | ‚úÖ S√ç | **llamarketing** | Keywords: funnel+ventas + lead+nurturing |

---

## üéØ Flujo de Decisi√≥n (Diagrama)

```
User Input
    ‚Üì
TRM-Router
    ‚Üì
Skill Detection (programming/marketing/etc)
    ‚Üì
detect_specialized_skill(query, scores)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚Üì                  ‚Üì                    ‚Üì                  ‚Üì
"qwen_coder"      "llamarketing"       None               soft > 0.7
(dev avanzado)    (marketing nicho)    (gen√©rico)         (emocional)
    ‚Üì                  ‚Üì                    ‚Üì                  ‚Üì
Qwen2.5-Coder     LLaMarketing         SOLAR              LFM2
(2048 ctx)        (2048 ctx)           (512/2048 ctx)     (2048 ctx)
    ‚Üì                  ‚Üì                    ‚Üì                  ‚Üì
Response          Response             Response           Response
```

---

## üìù Implementaci√≥n Paso a Paso

### Paso 1: Actualizar `core/skill_configs.py`

```python
# A√±adir funci√≥n detect_specialized_skill() con criterios long-tail
# Ver c√≥digo completo arriba
```

### Paso 2: Actualizar `core/mcp.py`

```python
def route_to_model(self, state: State) -> str:
    """Routing con modelos especializados"""
    # Ver c√≥digo completo arriba
```

### Paso 3: Actualizar `config/models.yaml`

```yaml
# A√±adir qwen25_coder_long y llamarketing_long
# Ver configuraci√≥n completa arriba
```

### Paso 4: Actualizar `.env`

```bash
# A√±adir QWEN_CODER_MODEL_NAME y LLAMARKETING_MODEL_NAME
# Ver configuraci√≥n completa arriba
```

### Paso 5: Validar con Tests

```python
# tests/test_specialized_routing.py
def test_qwen_coder_routing():
    """Valida routing a Qwen2.5-Coder para dev avanzado"""
    query = "Dise√±a arquitectura microservicios con Docker y Kubernetes"
    
    scores = trm_router.invoke(query)
    specialized = detect_specialized_skill(query, scores)
    
    assert specialized == "qwen_coder"
    
    model = mcp.route_to_model({"input": query, **scores})
    assert model == "qwen25_coder_long"

def test_llamarketing_routing():
    """Valida routing a LLaMarketing para marketing nicho"""
    query = "Crea copy publicitario para campa√±a omnicanal con an√°lisis de conversi√≥n"
    
    scores = trm_router.invoke(query)
    specialized = detect_specialized_skill(query, scores)
    
    assert specialized == "llamarketing"
    
    model = mcp.route_to_model({"input": query, **scores})
    assert model == "llamarketing_long"

def test_solar_generic_routing():
    """Valida que preguntas b√°sicas van a SOLAR"""
    query = "¬øQu√© es Python y para qu√© sirve?"
    
    scores = trm_router.invoke(query)
    specialized = detect_specialized_skill(query, scores)
    
    assert specialized is None  # No especializado
    
    model = mcp.route_to_model({"input": query, **scores})
    assert model == "solar_short"  # Gen√©rico
```

---

## üìä An√°lisis de Impacto

### RAM (Sin Cambios - Ollama Remoto)

| Modelo | Backend | RAM Local | Estado |
|--------|---------|-----------|--------|
| LFM2-1.2B | GGUF local | ~700 MB | Siempre en memoria |
| SOLAR-10.7B | Ollama remoto | 0 MB | On-demand |
| Qwen3-VL-4B | Multimodal local | ~3.5 GB | On-demand |
| **Qwen2.5-Coder-7B** | **Ollama remoto** | **0 MB** | **On-demand** |
| **LLaMarketing-8B** | **Ollama remoto** | **0 MB** | **On-demand** |
| **Total P99** | - | **~4.2 GB** | **‚úÖ Sin cambios** |

**Conclusi√≥n**: 0 impacto en RAM local (todos los modelos externos usan Ollama) ‚úÖ

---

### Complejidad de C√≥digo

| Aspecto | Antes v2.14 | Despu√©s v2.14+ | Impacto |
|---------|-------------|----------------|---------|
| Modelos en .env | 1 (SOLAR) | 3 (SOLAR, Qwen, LLaMarketing) | +2 variables |
| Modelos en models.yaml | 5 | 7 | +2 configs |
| Funci√≥n routing | `route_to_model()` | `detect_specialized_skill()` + `route_to_model()` | +1 funci√≥n |
| LOC a√±adidas | - | ~150 LOC | Moderado |
| Tests a√±adidos | - | 3 tests | +3 tests |

**Conclusi√≥n**: Complejidad moderada, pero justificada por especializaci√≥n ‚úÖ

---

### Beneficios vs Trade-offs

| Aspecto | Beneficio | Trade-off |
|---------|-----------|-----------|
| **Especializaci√≥n dev** | Qwen2.5-Coder mejor en arquitectura/debugging | Routing m√°s complejo |
| **Especializaci√≥n marketing** | LLaMarketing mejor en copy/campa√±as | +1 modelo a mantener |
| **Filosof√≠a Phoenix** | ‚ö†Ô∏è A√±ade modelos, pero con criterio claro | Requiere long-tail matching preciso |
| **RAM** | ‚úÖ 0 impacto (Ollama remoto) | N/A |
| **Latencia** | Similar (~25s P50) | Posible overhead de routing (+50ms) |

**Veredicto**: **Beneficios superan trade-offs** si routing es preciso ‚úÖ

---

## üéØ Criterios de √âxito

### KPIs para Validar Implementaci√≥n

1. **Precisi√≥n de Routing** (>90%):
   - Queries de dev avanzado ‚Üí Qwen2.5-Coder (>90% accuracy)
   - Queries de marketing nicho ‚Üí LLaMarketing (>90% accuracy)
   - Queries gen√©ricas ‚Üí SOLAR (>90% accuracy)

2. **Calidad de Respuestas** (benchmark):
   - Qwen2.5-Coder en dev avanzado > SOLAR (>15% mejora)
   - LLaMarketing en copy > SOLAR (>15% mejora)
   - SOLAR en gen√©rico = baseline (sin regresi√≥n)

3. **Latencia** (sin degradaci√≥n):
   - Overhead routing: <100ms
   - Latencia P50 total: ‚â§25s (sin cambios vs v2.14 baseline)

4. **Usabilidad**:
   - 0 configuraci√≥n manual de usuario
   - Routing autom√°tico transparente
   - Fallback a SOLAR si modelo especializado no disponible

---

## üöÄ Plan de Implementaci√≥n

### Fase 1: Configuraci√≥n (30 min)

1. ‚úÖ A√±adir modelos a `config/models.yaml`
2. ‚úÖ Actualizar `.env.example` con nuevas variables
3. ‚úÖ Documentar criterios de routing

### Fase 2: C√≥digo (1h)

1. ‚úÖ Implementar `detect_specialized_skill()` en `core/skill_configs.py`
2. ‚úÖ Actualizar `route_to_model()` en `core/mcp.py`
3. ‚úÖ A√±adir long-tail patterns para dev avanzado y marketing nicho

### Fase 3: Tests (30 min)

1. ‚úÖ Tests de routing especializado (`tests/test_specialized_routing.py`)
2. ‚úÖ Tests de fallback a SOLAR
3. ‚úÖ Tests de precisi√≥n de long-tail matching

### Fase 4: Validaci√≥n (1h)

1. ‚úÖ Ejecutar benchmark de routing accuracy
2. ‚úÖ Validar calidad de respuestas con queries reales
3. ‚úÖ Medir latencia overhead

### Fase 5: Documentaci√≥n (30 min)

1. ‚úÖ Actualizar README con modelos especializados
2. ‚úÖ Documentar criterios de routing
3. ‚úÖ Ejemplos de uso

**Total estimado**: ~3 horas de implementaci√≥n completa

---

## üí° Filosof√≠a Actualizada

**Mantra v2.14 Modelos Especializados**:

> _"SARAi usa especializaci√≥n cuando el nicho lo justifica.  
> SOLAR es el gen√©rico competente. Qwen y LLaMarketing son los expertos  
> que solo intervienen cuando la tarea es claramente de su dominio.  
> El routing debe ser preciso: mejor SOLAR gen√©rico que especialista equivocado."_

**Reglas actualizadas**:
1. **Default**: SOLAR (gen√©rico competente)
2. **Especializaci√≥n**: Solo para nichos claros (dev avanzado, marketing t√©cnico)
3. **Routing**: Long-tail matching con pesos ‚â•2.5
4. **Fallback**: Siempre SOLAR si duda
5. **Validaci√≥n**: Benchmark antes de producci√≥n

---

## ‚úÖ Checklist Final

- [ ] `config/models.yaml`: A√±adir qwen25_coder_long y llamarketing_long
- [ ] `.env.example`: A√±adir QWEN_CODER_MODEL_NAME y LLAMARKETING_MODEL_NAME
- [ ] `core/skill_configs.py`: Implementar detect_specialized_skill()
- [ ] `core/mcp.py`: Actualizar route_to_model()
- [ ] `tests/test_specialized_routing.py`: 3 tests de routing
- [ ] Ejecutar tests: `pytest tests/test_specialized_routing.py -v`
- [ ] Benchmark routing accuracy (>90% objetivo)
- [ ] Validar con queries reales
- [ ] Documentar en README
- [ ] Commit: "feat: modelos especializados Qwen2.5-Coder + LLaMarketing con routing inteligente"

---

**Creado**: 2025-11-01  
**Versi√≥n**: v2.14+  
**Status**: Propuesta de implementaci√≥n  
**Next**: ¬øApruebas para implementar?
