# ğŸ¯ Modelos Especializados - ImplementaciÃ³n v2.14

**Fecha**: 2025-11-01  
**Estrategia**: EspecializaciÃ³n por nicho con routing inteligente  
**FilosofÃ­a**: Skills como prompts + Modelos especializados para nichos crÃ­ticos

---

## ğŸ§  Planteamiento Validado

### Uso EstratÃ©gico de Modelos Especializados

**Tu criterio** (validado y aprobado):

1. **LLaMarketing-8B**: Para solicitudes **muy especÃ­ficas de marketing** (no genÃ©ricas)
   - Copy publicitario avanzado
   - CampaÃ±as multi-canal
   - SEO tÃ©cnico
   - **NO para**: "Escribe un email" o "Crea un tweet"

2. **Qwen2.5-Coder-7B**: Para **tareas avanzadas de desarrollo** (no bÃ¡sicas)
   - Arquitectura de sistemas complejos
   - Debugging profundo
   - Code review tÃ©cnico
   - **NO para**: "Â¿QuÃ© es Python?" o "Explica loops"

3. **SOLAR-10.7B**: Para **todo lo demÃ¡s** (general purpose)
   - Preguntas genÃ©ricas
   - Razonamiento general
   - Explicaciones tÃ©cnicas bÃ¡sicas

---

## ğŸ“‹ Sistema de Routing Inteligente

### Nivel 1: TRM-Router (ClasificaciÃ³n Base)

```python
# core/trm_classifier.py
scores = trm_router.invoke(user_input)
# {
#   "hard": 0.85,
#   "soft": 0.15,
#   "programming": 0.9,   # Skill detectado
#   "marketing": 0.1
# }
```

### Nivel 2: Skill Detection (Long-tail Matching)

```python
# core/skill_configs.py
def detect_specialized_skill(query: str, scores: dict) -> Optional[str]:
    """
    Detecta si la query requiere modelo especializado
    
    Returns:
        - "qwen_coder": Qwen2.5-Coder-7B (dev avanzado)
        - "llamarketing": LLaMarketing-8B (marketing nicho)
        - None: Usar SOLAR (genÃ©rico)
    """
    
    # CRITERIO 1: Qwen2.5-Coder (desarrollo avanzado)
    # Solo si: skill=programming Y complejidad alta
    if scores.get("programming", 0) > 0.7:
        # Keywords de complejidad avanzada
        advanced_dev_keywords = [
            # Arquitectura
            ("arquitectura", "microservicios", 3.0),
            ("diseÃ±o", "sistema", 2.5),
            ("patrones", "diseÃ±o", 2.5),
            
            # Debugging profundo
            ("debug", "segfault", 3.0),
            ("memory", "leak", 3.0),
            ("profiling", "performance", 2.5),
            
            # Code review tÃ©cnico
            ("refactor", "cÃ³digo", 2.5),
            ("optimizaciÃ³n", "algoritmo", 3.0),
            ("complejidad", "temporal", 2.5),
        ]
        
        for word1, word2, weight in advanced_dev_keywords:
            if word1 in query.lower() and word2 in query.lower():
                if weight >= 2.5:
                    return "qwen_coder"
    
    # CRITERIO 2: LLaMarketing (marketing nicho)
    # Solo si: keywords muy especÃ­ficos de marketing
    marketing_niche_keywords = [
        # Copy avanzado
        ("copy", "publicitario", 3.0),
        ("anuncio", "conversiÃ³n", 3.0),
        
        # CampaÃ±as multi-canal
        ("campaÃ±a", "omnicanal", 3.0),
        ("estrategia", "marketing", 2.5),
        
        # SEO tÃ©cnico
        ("seo", "tÃ©cnico", 3.0),
        ("keyword", "research", 2.5),
        
        # Funnel de ventas
        ("funnel", "ventas", 2.5),
        ("lead", "nurturing", 3.0),
    ]
    
    for word1, word2, weight in marketing_niche_keywords:
        if word1 in query.lower() and word2 in query.lower():
            if weight >= 2.5:
                return "llamarketing"
    
    # DEFAULT: SOLAR (genÃ©rico)
    return None
```

### Nivel 3: MCP Routing (SelecciÃ³n de Modelo)

```python
# core/mcp.py
def route_to_model(self, state: State) -> str:
    """
    Routing inteligente a modelo especializado o genÃ©rico
    
    Prioridad:
      1. EspecializaciÃ³n nicho (Qwen/LLaMarketing)
      2. GenÃ©rico competente (SOLAR)
      3. Tiny fallback (LFM2)
    """
    
    # Detectar skill especializado
    from core.skill_configs import detect_specialized_skill
    specialized = detect_specialized_skill(state["input"], state)
    
    if specialized == "qwen_coder":
        return "qwen25_coder_long"  # Desarrollo avanzado
    
    elif specialized == "llamarketing":
        return "llamarketing_long"  # Marketing nicho
    
    # DEFAULT: SOLAR (genÃ©rico)
    elif state["hard"] > 0.7:
        context_len = len(state["input"])
        return "solar_long" if context_len > 400 else "solar_short"
    
    # Fallback: LFM2 (soft-skills)
    else:
        return "lfm2"
```

---

## ğŸ“¦ ConfiguraciÃ³n models.yaml

### Modelos Especializados (NUEVOS)

```yaml
# ----------------------------------------------------------------------------
# MODELOS ESPECIALIZADOS - OLLAMA REMOTE
# ----------------------------------------------------------------------------

qwen25_coder_long:
  name: "Qwen2.5-Coder-7B-Instruct (Long Context)"
  type: "text"
  backend: "ollama"
  
  # EspecializaciÃ³n: Desarrollo avanzado, arquitectura, debugging
  # NO usar para: Preguntas bÃ¡sicas de programaciÃ³n
  # Routing: Solo si detect_specialized_skill() == "qwen_coder"
  
  api_url: "${OLLAMA_BASE_URL}"
  model_name: "${QWEN_CODER_MODEL_NAME}"
  
  # Contexto largo para anÃ¡lisis de cÃ³digo complejo
  n_ctx: 2048
  
  # Temperatura baja (determinista para cÃ³digo)
  temperature: 0.3
  max_tokens: 1024
  top_p: 0.9
  
  # GestiÃ³n de memoria
  load_on_demand: true
  priority: 7  # Media-alta (especializado)
  max_memory_mb: 0  # Ollama remoto

llamarketing_long:
  name: "LLaMarketing-8B (Long Context)"
  type: "text"
  backend: "ollama"
  
  # EspecializaciÃ³n: Marketing nicho (copy, campaÃ±as, SEO tÃ©cnico)
  # NO usar para: Emails genÃ©ricos, tweets simples
  # Routing: Solo si detect_specialized_skill() == "llamarketing"
  
  api_url: "${OLLAMA_BASE_URL}"
  model_name: "${LLAMARKETING_MODEL_NAME}"
  
  # Contexto largo para campaÃ±as multi-canal
  n_ctx: 2048
  
  # Temperatura alta (creatividad)
  temperature: 0.9
  max_tokens: 1024
  top_p: 0.95
  
  # GestiÃ³n de memoria
  load_on_demand: true
  priority: 6  # Media (nicho especÃ­fico)
  max_memory_mb: 0  # Ollama remoto
```

---

## ğŸ”§ Variables .env

### ConfiguraciÃ³n Completa

```bash
# ============================================================================
# MODELOS EXTERNOS - OLLAMA REMOTE
# ============================================================================

# Servidor Ollama
OLLAMA_BASE_URL=http://192.168.0.251:11434

# Modelo genÃ©rico (hard-skills general)
SOLAR_MODEL_NAME=una-solar-10.7b-instruct-v1.0-q4

# Modelo especializado: Desarrollo avanzado
# Uso: Arquitectura, debugging profundo, code review tÃ©cnico
# NO usar para: Preguntas bÃ¡sicas de Python, "Â¿QuÃ© es un loop?"
QWEN_CODER_MODEL_NAME=qwen2.5-coder:7b-instruct

# Modelo especializado: Marketing nicho
# Uso: Copy publicitario, campaÃ±as omnicanal, SEO tÃ©cnico
# NO usar para: Emails genÃ©ricos, tweets simples
LLAMARKETING_MODEL_NAME=llamarketing:8b
```

---

## ğŸ“Š Matriz de DecisiÃ³n de Routing

### Ejemplos de Queries y Routing

| Query | Skill | Especializado? | Modelo | RazÃ³n |
|-------|-------|----------------|--------|-------|
| "Â¿QuÃ© es Python?" | programming | âŒ NO | **solar_short** | Pregunta bÃ¡sica â†’ genÃ©rico |
| "Explica loops" | programming | âŒ NO | **solar_short** | Conceptos bÃ¡sicos â†’ genÃ©rico |
| "Arquitectura microservicios Docker" | programming | âœ… SÃ | **qwen25_coder** | Keywords: arquitectura+microservicios (3.0) |
| "Debug segfault en C++" | programming | âœ… SÃ | **qwen25_coder** | Keywords: debug+segfault (3.0) |
| "OptimizaciÃ³n algoritmo O(nÂ²) â†’ O(n log n)" | programming | âœ… SÃ | **qwen25_coder** | Keywords: optimizaciÃ³n+algoritmo (3.0) |
| "Escribe un email profesional" | - | âŒ NO | **solar_short** | No es marketing nicho â†’ genÃ©rico |
| "Crea un tweet sobre IA" | - | âŒ NO | **solar_short** | Social media simple â†’ genÃ©rico |
| "Copy publicitario campaÃ±a multi-canal" | marketing | âœ… SÃ | **llamarketing** | Keywords: copy+publicitario (3.0) |
| "Estrategia SEO tÃ©cnico schema markup" | marketing | âœ… SÃ | **llamarketing** | Keywords: seo+tÃ©cnico (3.0) |
| "Funnel de ventas lead nurturing" | marketing | âœ… SÃ | **llamarketing** | Keywords: funnel+ventas + lead+nurturing |

---

## ğŸ¯ Flujo de DecisiÃ³n (Diagrama)

```
User Input
    â†“
TRM-Router
    â†“
Skill Detection (programming/marketing/etc)
    â†“
detect_specialized_skill(query, scores)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â†“                  â†“                    â†“                  â†“
"qwen_coder"      "llamarketing"       None               soft > 0.7
(dev avanzado)    (marketing nicho)    (genÃ©rico)         (emocional)
    â†“                  â†“                    â†“                  â†“
Qwen2.5-Coder     LLaMarketing         SOLAR              LFM2
(2048 ctx)        (2048 ctx)           (512/2048 ctx)     (2048 ctx)
    â†“                  â†“                    â†“                  â†“
Response          Response             Response           Response
```

---

## ğŸ“ ImplementaciÃ³n Paso a Paso

### Paso 1: Actualizar `core/skill_configs.py`

```python
# AÃ±adir funciÃ³n detect_specialized_skill() con criterios long-tail
# Ver cÃ³digo completo arriba
```

### Paso 2: Actualizar `core/mcp.py`

```python
def route_to_model(self, state: State) -> str:
    """Routing con modelos especializados"""
    # Ver cÃ³digo completo arriba
```

### Paso 3: Actualizar `config/models.yaml`

```yaml
# AÃ±adir qwen25_coder_long y llamarketing_long
# Ver configuraciÃ³n completa arriba
```

### Paso 4: Actualizar `.env`

```bash
# AÃ±adir QWEN_CODER_MODEL_NAME y LLAMARKETING_MODEL_NAME
# Ver configuraciÃ³n completa arriba
```

### Paso 5: Validar con Tests

```python
# tests/test_specialized_routing.py
def test_qwen_coder_routing():
    """Valida routing a Qwen2.5-Coder para dev avanzado"""
    query = "DiseÃ±a arquitectura microservicios con Docker y Kubernetes"
    
    scores = trm_router.invoke(query)
    specialized = detect_specialized_skill(query, scores)
    
    assert specialized == "qwen_coder"
    
    model = mcp.route_to_model({"input": query, **scores})
    assert model == "qwen25_coder_long"

def test_llamarketing_routing():
    """Valida routing a LLaMarketing para marketing nicho"""
    query = "Crea copy publicitario para campaÃ±a omnicanal con anÃ¡lisis de conversiÃ³n"
    
    scores = trm_router.invoke(query)
    specialized = detect_specialized_skill(query, scores)
    
    assert specialized == "llamarketing"
    
    model = mcp.route_to_model({"input": query, **scores})
    assert model == "llamarketing_long"

def test_solar_generic_routing():
    """Valida que preguntas bÃ¡sicas van a SOLAR"""
    query = "Â¿QuÃ© es Python y para quÃ© sirve?"
    
    scores = trm_router.invoke(query)
    specialized = detect_specialized_skill(query, scores)
    
    assert specialized is None  # No especializado
    
    model = mcp.route_to_model({"input": query, **scores})
    assert model == "solar_short"  # GenÃ©rico
```

---

## ğŸ“Š AnÃ¡lisis de Impacto

### RAM (Sin Cambios - Ollama Remoto)

| Modelo | Backend | RAM Local | Estado |
|--------|---------|-----------|--------|
| LFM2-1.2B | GGUF local | ~700 MB | Siempre en memoria |
| SOLAR-10.7B | Ollama remoto | 0 MB | On-demand |
| Qwen3-VL-4B | Multimodal local | ~3.5 GB | On-demand |
| **Qwen2.5-Coder-7B** | **Ollama remoto** | **0 MB** | **On-demand** |
| **LLaMarketing-8B** | **Ollama remoto** | **0 MB** | **On-demand** |
| **Total P99** | - | **~4.2 GB** | **âœ… Sin cambios** |

**ConclusiÃ³n**: 0 impacto en RAM local (todos los modelos externos usan Ollama) âœ…

---

### Complejidad de CÃ³digo

| Aspecto | Antes v2.14 | DespuÃ©s v2.14+ | Impacto |
|---------|-------------|----------------|---------|
| Modelos en .env | 1 (SOLAR) | 3 (SOLAR, Qwen, LLaMarketing) | +2 variables |
| Modelos en models.yaml | 5 | 7 | +2 configs |
| FunciÃ³n routing | `route_to_model()` | `detect_specialized_skill()` + `route_to_model()` | +1 funciÃ³n |
| LOC aÃ±adidas | - | ~150 LOC | Moderado |
| Tests aÃ±adidos | - | 3 tests | +3 tests |

**ConclusiÃ³n**: Complejidad moderada, pero justificada por especializaciÃ³n âœ…

---

### Beneficios vs Trade-offs

| Aspecto | Beneficio | Trade-off |
|---------|-----------|-----------|
| **EspecializaciÃ³n dev** | Qwen2.5-Coder mejor en arquitectura/debugging | Routing mÃ¡s complejo |
| **EspecializaciÃ³n marketing** | LLaMarketing mejor en copy/campaÃ±as | +1 modelo a mantener |
| **FilosofÃ­a Phoenix** | âš ï¸ AÃ±ade modelos, pero con criterio claro | Requiere long-tail matching preciso |
| **RAM** | âœ… 0 impacto (Ollama remoto) | N/A |
| **Latencia** | Similar (~25s P50) | Posible overhead de routing (+50ms) |

**Veredicto**: **Beneficios superan trade-offs** si routing es preciso âœ…

---

## ğŸ¯ Criterios de Ã‰xito

### KPIs para Validar ImplementaciÃ³n

1. **PrecisiÃ³n de Routing** (>90%):
   - Queries de dev avanzado â†’ Qwen2.5-Coder (>90% accuracy)
   - Queries de marketing nicho â†’ LLaMarketing (>90% accuracy)
   - Queries genÃ©ricas â†’ SOLAR (>90% accuracy)

2. **Calidad de Respuestas** (benchmark):
   - Qwen2.5-Coder en dev avanzado > SOLAR (>15% mejora)
   - LLaMarketing en copy > SOLAR (>15% mejora)
   - SOLAR en genÃ©rico = baseline (sin regresiÃ³n)

3. **Latencia** (sin degradaciÃ³n):
   - Overhead routing: <100ms
   - Latencia P50 total: â‰¤25s (sin cambios vs v2.14 baseline)

4. **Usabilidad**:
   - 0 configuraciÃ³n manual de usuario
   - Routing automÃ¡tico transparente
   - Fallback a SOLAR si modelo especializado no disponible

---

## ğŸš€ Plan de ImplementaciÃ³n

### Fase 1: ConfiguraciÃ³n (30 min)

1. âœ… AÃ±adir modelos a `config/models.yaml`
2. âœ… Actualizar `.env.example` con nuevas variables
3. âœ… Documentar criterios de routing

### Fase 2: CÃ³digo (1h)

1. âœ… Implementar `detect_specialized_skill()` en `core/skill_configs.py`
2. âœ… Actualizar `route_to_model()` en `core/mcp.py`
3. âœ… AÃ±adir long-tail patterns para dev avanzado y marketing nicho

### Fase 3: Tests (30 min)

1. âœ… Tests de routing especializado (`tests/test_specialized_routing.py`)
2. âœ… Tests de fallback a SOLAR
3. âœ… Tests de precisiÃ³n de long-tail matching

### Fase 4: ValidaciÃ³n (1h)

1. âœ… Ejecutar benchmark de routing accuracy
2. âœ… Validar calidad de respuestas con queries reales
3. âœ… Medir latencia overhead

### Fase 5: DocumentaciÃ³n (30 min)

1. âœ… Actualizar README con modelos especializados
2. âœ… Documentar criterios de routing
3. âœ… Ejemplos de uso

**Total estimado**: ~3 horas de implementaciÃ³n completa

---

## ğŸ’¡ FilosofÃ­a Actualizada

**Mantra v2.14 Modelos Especializados**:

> _"SARAi usa especializaciÃ³n cuando el nicho lo justifica.  
> SOLAR es el genÃ©rico competente. Qwen y LLaMarketing son los expertos  
> que solo intervienen cuando la tarea es claramente de su dominio.  
> El routing debe ser preciso: mejor SOLAR genÃ©rico que especialista equivocado."_

**Reglas actualizadas**:
1. **Default**: SOLAR (genÃ©rico competente)
2. **EspecializaciÃ³n**: Solo para nichos claros (dev avanzado, marketing tÃ©cnico)
3. **Routing**: Long-tail matching con pesos â‰¥2.5
4. **Fallback**: Siempre SOLAR si duda
5. **ValidaciÃ³n**: Benchmark antes de producciÃ³n

---

## âœ… Checklist Final

- [ ] `config/models.yaml`: AÃ±adir qwen25_coder_long y llamarketing_long
- [ ] `.env.example`: AÃ±adir QWEN_CODER_MODEL_NAME y LLAMARKETING_MODEL_NAME
- [ ] `core/skill_configs.py`: Implementar detect_specialized_skill()
- [ ] `core/mcp.py`: Actualizar route_to_model()
- [ ] `tests/test_specialized_routing.py`: 3 tests de routing
- [ ] Ejecutar tests: `pytest tests/test_specialized_routing.py -v`
- [ ] Benchmark routing accuracy (>90% objetivo)
- [ ] Validar con queries reales
- [ ] Documentar en README
- [ ] Commit: "feat: modelos especializados Qwen2.5-Coder + LLaMarketing con routing inteligente"

---

**Creado**: 2025-11-01  
**VersiÃ³n**: v2.14+  
**Status**: Propuesta de implementaciÃ³n  
**Next**: Â¿Apruebas para implementar?
