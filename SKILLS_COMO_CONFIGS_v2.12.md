# ğŸ”§ Skills como Configuraciones Especializadas (Estrategia Corregida v2.12)

## âŒ Malentendido Original

InterpretÃ© "Skills MoE" como:
- Cargar 6 LLMs diferentes (CodeLlama, Mistral, FinGPT, etc)
- +4.8 GB RAM
- GestiÃ³n compleja de modelos

## âœ… Realidad del Sistema

Los **skills son CONFIGURACIONES**, no modelos:

```yaml
skills:
  programming:
    model: "solar"  # â† Usa SOLAR, no CodeLlama
    temperature: 0.2  # Preciso para cÃ³digo
    system_prompt: |
      Eres un experto en programaciÃ³n. Responde con:
      - CÃ³digo limpio y comentado
      - Explicaciones tÃ©cnicas precisas
      - Ejemplos ejecutables
    domains: ["cÃ³digo", "programaciÃ³n", "python", "debugging"]
    
  diagnosis:
    model: "solar"  # â† Usa SOLAR, no Mistral
    temperature: 0.3  # DiagnÃ³stico preciso
    system_prompt: |
      Eres un experto en diagnÃ³stico de sistemas. Analiza:
      - Logs de error sistemÃ¡ticamente
      - Causa raÃ­z (RCA)
      - Pasos de resoluciÃ³n
    domains: ["diagnÃ³stico", "error", "logs", "sistema"]
```

## ğŸ¯ Arquitectura Correcta

### Capa 1: TRM-Router con Heads Especializados

El TRM clasifica con **6 heads** (no solo hard/soft):

```python
class TRMClassifierSpecialized(nn.Module):
    def __init__(self):
        super().__init__()
        # ... cÃ³digo recursivo existente ...
        
        # 6 cabezas especializadas
        self.head_programming = nn.Linear(256, 1)
        self.head_diagnosis = nn.Linear(256, 1)
        self.head_finance = nn.Linear(256, 1)
        self.head_creative = nn.Linear(256, 1)
        self.head_reasoning = nn.Linear(256, 1)
        self.head_general = nn.Linear(256, 1)  # Fallback
    
    def forward(self, x_embedding):
        # ... recursiÃ³n TRM ...
        
        return {
            "programming": torch.sigmoid(self.head_programming(y)).item(),
            "diagnosis": torch.sigmoid(self.head_diagnosis(y)).item(),
            "finance": torch.sigmoid(self.head_finance(y)).item(),
            "creative": torch.sigmoid(self.head_creative(y)).item(),
            "reasoning": torch.sigmoid(self.head_reasoning(y)).item(),
            "general": torch.sigmoid(self.head_general(y)).item()
        }
```

### Capa 2: SkillConfigs (Prompts + ParÃ¡metros)

```python
# core/skill_configs.py
SKILL_CONFIGS = {
    "programming": {
        "model": "solar",  # Usa SOLAR existente
        "temperature": 0.2,
        "max_tokens": 512,
        "system_prompt": """Eres un experto en programaciÃ³n con 15 aÃ±os de experiencia.

DIRECTRICES:
- CÃ³digo limpio, idiomÃ¡tico y bien documentado
- Explicaciones tÃ©cnicas precisas sin simplificaciones
- Ejemplos ejecutables con manejo de errores
- Referencia buenas prÃ¡cticas (PEP-8, SOLID, etc)
- Si hay mÃºltiples soluciones, menciona trade-offs

FORMATO DE RESPUESTA:
1. ExplicaciÃ³n breve (2-3 lÃ­neas)
2. CÃ³digo con comentarios
3. Ejemplo de uso
4. Posibles edge cases""",
        "domains": ["cÃ³digo", "programaciÃ³n", "python", "javascript", "debugging"]
    },
    
    "diagnosis": {
        "model": "solar",
        "temperature": 0.3,
        "max_tokens": 512,
        "system_prompt": """Eres un experto en diagnÃ³stico de sistemas y anÃ¡lisis de causa raÃ­z.

METODOLOGÃA:
1. RecolecciÃ³n de sÃ­ntomas y evidencia
2. AnÃ¡lisis sistemÃ¡tico (logs, mÃ©tricas, estado)
3. HipÃ³tesis ordenadas por probabilidad
4. Pasos de verificaciÃ³n concretos
5. SoluciÃ³n con prevenciÃ³n futura

FORMATO DE RESPUESTA:
## DiagnÃ³stico
- SÃ­ntoma principal: ...
- Evidencia: ...

## Causa RaÃ­z Probable
...

## Pasos de ResoluciÃ³n
1. ...
2. ...""",
        "domains": ["diagnÃ³stico", "error", "logs", "sistema", "fallo"]
    },
    
    "finance": {
        "model": "solar",
        "temperature": 0.4,
        "max_tokens": 512,
        "system_prompt": """Eres un analista financiero certificado (CFA Level II).

ENFOQUE:
- AnÃ¡lisis cuantitativo riguroso
- Citas de mÃ©tricas estÃ¡ndar (ROI, IRR, P/E, etc)
- ConsideraciÃ³n de riesgos y volatilidad
- Contexto macroeconÃ³mico cuando relevante
- Disclaimers de inversiÃ³n apropiados

FORMATO:
## AnÃ¡lisis
- MÃ©tricas clave: ...
- Tendencia: ...

## RecomendaciÃ³n
...

## Riesgos
...""",
        "domains": ["finanzas", "inversiÃ³n", "mercado", "roi"]
    },
    
    "creative": {
        "model": "lfm2",  # Usa LFM2 para creatividad
        "temperature": 0.9,  # Alta creatividad
        "max_tokens": 512,
        "system_prompt": """Eres un escritor creativo galardonado.

DIRECTRICES:
- Narrativa envolvente con detalles sensoriales
- Desarrollo de personajes profundo
- DiÃ¡logos naturales y distintivos
- Uso creativo del lenguaje (metÃ¡foras, sÃ­miles)
- Estructura narrativa sÃ³lida (setup, conflicto, resoluciÃ³n)

TONO: Adaptable segÃºn peticiÃ³n (poÃ©tico, humorÃ­stico, dramÃ¡tico, etc)""",
        "domains": ["historia", "cuento", "poema", "narrativa"]
    },
    
    "reasoning": {
        "model": "solar",
        "temperature": 0.5,
        "max_tokens": 512,
        "system_prompt": """Eres un experto en razonamiento lÃ³gico y pensamiento crÃ­tico.

METODOLOGÃA:
- Descomponer problemas complejos en pasos
- Identificar premisas y supuestos
- Aplicar lÃ³gica deductiva/inductiva
- Detectar falacias lÃ³gicas
- Verificar coherencia interna

FORMATO:
## AnÃ¡lisis del Problema
...

## Razonamiento Paso a Paso
1. Premisa: ...
2. Inferencia: ...
3. ConclusiÃ³n: ...

## VerificaciÃ³n
...""",
        "domains": ["razonamiento", "lÃ³gica", "anÃ¡lisis", "paso a paso"]
    },
    
    "general": {
        "model": "solar",
        "temperature": 0.7,
        "max_tokens": 512,
        "system_prompt": """Eres un asistente Ãºtil, preciso y conciso.

Responde de forma:
- Clara y estructurada
- TÃ©cnicamente correcta
- Adaptada al nivel del usuario
- Honesta sobre limitaciones""",
        "domains": []  # Fallback genÃ©rico
    }
}
```

### Capa 3: MCP con Skill Selection

```python
# core/mcp.py (NUEVO MÃ‰TODO)
def select_skill_and_generate(self, trm_scores: dict, user_input: str) -> str:
    """
    Selecciona skill basado en scores TRM y ejecuta con config especializada
    
    Args:
        trm_scores: {"programming": 0.85, "diagnosis": 0.12, ...}
        user_input: Consulta del usuario
    
    Returns:
        Respuesta generada con el skill apropiado
    """
    # 1. Seleccionar skill de mayor score
    best_skill = max(trm_scores.items(), key=lambda x: x[1])
    skill_name, confidence = best_skill
    
    # 2. Obtener configuraciÃ³n del skill
    skill_config = SKILL_CONFIGS[skill_name]
    
    # 3. Construir prompt especializado
    specialized_prompt = f"""{skill_config['system_prompt']}

# Consulta del Usuario
{user_input}

# Instrucciones
Responde segÃºn las directrices de {skill_name} con nivel de confianza {confidence:.2%}."""
    
    # 4. Seleccionar modelo apropiado
    model_name = skill_config['model']  # "solar" o "lfm2"
    model = self.model_pool.get(model_name)
    
    # 5. Generar con parÃ¡metros especializados
    response = model.generate(
        specialized_prompt,
        temperature=skill_config['temperature'],
        max_tokens=skill_config['max_tokens']
    )
    
    # 6. Log para feedback
    self.feedback_logger.log_skill_usage(
        skill=skill_name,
        confidence=confidence,
        model=model_name,
        input=user_input,
        output=response
    )
    
    return response
```

## ğŸ“Š ComparaciÃ³n de Estrategias

| Aspecto | âŒ Skills como LLMs | âœ… Skills como Configs |
|---------|---------------------|------------------------|
| **Modelos en RAM** | 7 (SOLAR + 6 skills) | 2 (SOLAR + LFM2) |
| **RAM total** | ~11.6 GB | ~900 MB |
| **Latencia** | Alta (carga modelo) | Baja (mismo modelo) |
| **EspecializaciÃ³n** | Limitada al LLM | Alta (prompts expertos) |
| **Mantenibilidad** | Compleja (6 GGUFs) | Simple (1 YAML) |
| **Aprendizaje TRM** | No | SÃ­ (scores â†’ mejor routing) |

## ğŸ¯ Plan de ImplementaciÃ³n Corregido

### T1.1-FINAL: Skill Configs + TRM Heads (8h)

**Archivos**:
- `core/skill_configs.py`: Diccionario SKILL_CONFIGS (NEW)
- `core/trm_classifier.py`: AÃ±adir 6 heads especializados (+30 LOC)
- `core/mcp.py`: MÃ©todo `select_skill_and_generate()` (+60 LOC)

**Tests**:
- `test_skill_configs.py`: Validar que cada skill tiene system_prompt, temperature
- `test_trm_specialized.py`: Verificar que TRM clasifica correctamente (>85% accuracy)
- `test_mcp_skill_selection.py`: E2E con prompt especializado

**Dataset de entrenamiento**:
```python
# scripts/generate_skill_dataset.py
import random

def generate_skill_queries():
    """Genera 10K queries sintÃ©ticas con SOLAR pre-clasificadas"""
    
    queries = {
        "programming": [
            "Â¿CÃ³mo implemento un decorador en Python?",
            "Explica el patrÃ³n Observer con cÃ³digo",
            "Debug este error: AttributeError en lÃ­nea 42"
        ],
        "diagnosis": [
            "Mi servidor devuelve 502 Bad Gateway",
            "Docker container reinicia constantemente",
            "RAM al 98% pero sin proceso culpable"
        ],
        # ... 10K total
    }
    
    # Generar embeddings con EmbeddingGemma
    # Guardar en data/trm_skill_dataset.npz
```

### T1.2-FINAL: Entrenar TRM con Skill Heads (10h)

```python
# scripts/train_trm_skills.py
def train_trm_specialized():
    """
    Entrena TRM-Router con 6 heads especializados
    Dataset: 10K queries (data/trm_skill_dataset.npz)
    Target accuracy: >85% por skill
    """
    
    # Arquitectura: Shared trunk + 6 independent heads
    # Loss: Multi-label BCE (una query puede activar mÃºltiples skills)
    # Optimizer: AdamW con lr=1e-4
    # Epochs: 50 con early stopping
```

### T1.3-FINAL: MCP Skill Selection (6h)

- Integrar `select_skill_and_generate()` en `core/graph.py`
- Routing: TRM scores â†’ Skill config â†’ SOLAR/LFM2 con prompt especializado
- Feedback loop: Ajustar TRM basado en calidad de respuestas

## ğŸ” Ejemplo de Flujo Completo

**Input**: "Â¿CÃ³mo optimizo esta consulta SQL lenta?"

**1. TRM-Router**:
```python
scores = {
    "programming": 0.72,  # SQL es programaciÃ³n
    "diagnosis": 0.65,    # "lenta" sugiere diagnÃ³stico
    "finance": 0.05,
    "creative": 0.02,
    "reasoning": 0.35,
    "general": 0.20
}
# Selecciona: programming (0.72)
```

**2. Skill Config**:
```python
skill = SKILL_CONFIGS["programming"]
# temperature: 0.2 (precisiÃ³n)
# system_prompt: "Eres experto en programaciÃ³n..."
```

**3. Prompt Especializado**:
```
Eres un experto en programaciÃ³n con 15 aÃ±os de experiencia.

DIRECTRICES:
- CÃ³digo limpio, idiomÃ¡tico y bien documentado
[...]

# Consulta del Usuario
Â¿CÃ³mo optimizo esta consulta SQL lenta?

# Instrucciones
Responde segÃºn directrices de programming con nivel de confianza 72%.
```

**4. SOLAR genera con temp=0.2**:
```
## AnÃ¡lisis de OptimizaciÃ³n SQL

1. **IndexaciÃ³n**:
   - Crea Ã­ndices en columnas de WHERE/JOIN
   [cÃ³digo especÃ­fico]

2. **EXPLAIN ANALYZE**:
   ```sql
   EXPLAIN ANALYZE
   SELECT ...
   ```
   
[respuesta tÃ©cnica precisa]
```

## âœ… Beneficios de esta Estrategia

1. **RAM**: 900 MB vs 11.6 GB (ahorro 92%)
2. **EspecializaciÃ³n**: Prompts expertos >> LLMs genÃ©ricos de 7B
3. **Latencia**: Sin carga de modelos (SOLAR ya en RAM)
4. **Aprendizaje**: TRM mejora routing con feedback
5. **Mantenibilidad**: Editar YAML >> reentrenar LLMs

## ğŸ“¦ Archivos Nuevos/Modificados

**CREAR**:
- âœ… `core/skill_configs.py` (+180 LOC)
- âœ… `scripts/generate_skill_dataset.py` (+200 LOC)
- âœ… `scripts/train_trm_skills.py` (+150 LOC)
- âœ… `tests/test_skill_configs.py` (+120 LOC)

**MODIFICAR**:
- âœ… `core/trm_classifier.py`: +6 heads (+30 LOC)
- âœ… `core/mcp.py`: `select_skill_and_generate()` (+60 LOC)
- âœ… `core/graph.py`: Integrar skill selection (+25 LOC)

**NO MODIFICAR**:
- âŒ `core/model_pool.py`: NO skills_cache (usa SOLAR/LFM2 existentes)
- âŒ `config/sarai.yaml`: Skills quedan como referencia, no se cargan

**Total**: +765 LOC (vs +970 LOC incorrecto)

---

**ConclusiÃ³n**: Los skills SON PROMPTS ESPECIALIZADOS + CONFIGS, no modelos separados. El TRM aprende a routear, el MCP selecciona el skill, y SOLAR/LFM2 generan con contexto especializado. ğŸ¯
