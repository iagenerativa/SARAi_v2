# ESTADO 31-10-2025

## 1. Resumen de la conversación
- Objetivos principales: El usuario solicitó «Hazme un análisis desde la 2.0 hasta ahora de todo lo que llevamos con su porcentaje… y analiza el proyecto total en la documentación para ver si se nos ha pasado algo por alto. El proyecto tiene que ser coherente, persistente, eficiente…». Después confirmó la continuidad («¿Desea continuar con la iteración?») y finalmente pidió un resumen estructurado con énfasis en el uso reciente de herramientas.
- Contexto de la sesión: Se revisaron los ficheros CHANGELOG/STATUS por versión, la arquitectura e implementaciones de referencia y los módulos núcleo para cuantificar el grado de avance, resaltando las brechas detectadas. Las acciones más recientes cubrieron la orquestación LangGraph y la localización de agentes omni nativos.
- Evolución de la intención: Partió de una auditoría de progreso end to end, pasó por validar que la iteración seguía activa y culminó en una recapitulación detallada alineada con los objetivos de coherencia y eficiencia del proyecto.

## 2. Tabla de evolución detallada (v2.0 – v2.16)

| Versión | Hito planificado | Avance actual | ETA restante | ¿Abordado en otra etapa? |
|---------|------------------|---------------|--------------|-------------------------|
| v2.0 | Arquitectura base (LangGraph + agentes SOLAR/LFM2) | 100% | 0h (completo) | Base vigente desde v2.0 |
| v2.0 | TRM-Router dual hard/soft (7M) | 100% | 0h (completo) | Refinamientos previstos en v2.7 |
| v2.1 | Calibración TRM-Router + dataset `router_training.npz` | 95% | ≈2h para validar thresholds | Ajuste final planificado para v2.7 |
| v2.1 | Instrumentación de métricas básicas y health endpoint | 80% | ≈4h (históricos automatizados) | Ampliada en v2.5 (`/metrics`) |
| v2.2 | Feedback implícito asíncrono (worker background) | 90% | ≈3h (firmas SHA/HMAC) | Endurecimiento previsto en v2.7 |
| v2.2 | Cache de embeddings para feedback incremental | 85% | ≈4h (tests + fallback) | Complementado parcialmente en v2.8 |
| v2.3 | Prefetcher TRM-Mini con debounce 300 ms | 95% | ≈1h (tests Pytest) | Activo desde v2.3 |
| v2.3 | MCP fast-cache semántica (VQ) | 90% | ≈3h (telemetría hits/miss) | Ajustes pendientes en v2.8 |
| v2.4 | Docker multi-stage + healthcheck Docker/K8s | 100% | 0h (completo) | Base de despliegue actual |
| v2.4 | Makefile `prod` (install→bench→health) | 95% | ≈2h (targets de pruebas) | Afinado previsto en v2.9 |
| v2.5 | Endpoint `/metrics` + exposición Prometheus | 85% | ≈3h (nuevos gauges/histogramas) | Extendida parcialmente en v2.10 |
| v2.5 | Dashboard Grafana automatizado | 60% | ≈6h (script publicación estable) | Script base en v2.6; pipeline aún manual |
| v2.6 | CI multi-arch + SBOM CycloneDX/SPDX | 90% | ≈2h (verificación post-push) | Usado en releases actuales |
| v2.6 | Firma Cosign OIDC + attestation hardware | 85% | ≈6h (attestation pendiente) | Pilar 6.6 planificado v2.7 |
| v2.7 | MoE real (skills hot-plug, LRU) | 50% | ≈12h (carga dinámica + tests) | Reprogramado para v2.12 (Skill Orchestrator) |
| v2.7 | Batching `llama.cpp` dinámico (n_parallel) | 40% | ≈10h (integrar `BatchPrioritizer`) | Aún no cubierto en master |
| v2.7 | Logs inmutables (SHA-256/HMAC por interacción) | 45% | ≈6h (sidecars + verificador) | Web/voz listos v2.10–v2.11; faltan logs generales |
| v2.8 | Auto-tuning MCP sin downtime (swap atómico) | 45% | ≈12h (entrenamiento real + validación) | Stub en `online_tune.py`; cierre previsto en v2.16 |
| v2.8 | Reentrenamiento nocturno + golden queries | 50% | ≈10h (scheduler + reporting) | Gating manual en v2.9; automatización pendiente |
| v2.9 | Sentinel 0% regresión (gating golden queries) | 70% | ≈4h (hook CI + alertas) | Dataset listo; falta integración pipeline |
| v2.9 | Fast lane crítico (latencia P99 ≤2 s) | 40% | ≈8h (activar priorizador + métricas) | `BatchPrioritizer` existe, no cableado |
| v2.10 | RAG autónomo (búsqueda + síntesis) | 80% | ≈6h (fallback y TTL diferenciados) | Operativo en master |
| v2.10 | Auditoría web firmada (SHA-256 + safe mode) | 70% | ≈5h (verificador CLI + alertas) | Necesita extenderse a interacción general |
| v2.11 | Audio Router con Sentinel fallback | 100% | 0h (completo) | En producción actual |
| v2.11 | Hardening Docker (omni_pipeline + searxng) | 100% | 0h (completo) | Base para servicios gRPC |
| v2.11 | Integración voz en LangGraph (nodo `process_voice`) | 60% | ≈4h (tests E2E) | Se planea cerrar en v2.16 |
| v2.11 | Servidor NLLB multi-idioma | 20% | ≈8h (container + integración) | Aún no abordado en otra versión |
| v2.12 | TRM-Router aprendizaje continuo (M1) | 40% | ≈3 días | En progreso; reemplaza MoE skills redundantes |
| v2.12 | Calibración dinámica TRM con feedback (M2) | 20% | ≈2 días | Infraestructura lista; falta entrenamiento real |
| v2.12 | Eliminación de skills redundantes (M3) | 0% | ≈1 día | SOLAR+LFM2 cubren programming/diagnosis/finance/creative/reasoning |
| v2.13 | Warm-up Sentience (blueprint inicial) | 30% | ≈3 días (documentación → código) | Parcial en `ROADMAP_v2.15`; ejecución trasladada a v2.16 |
| v2.14 | Omni Loop planning + KPIs | 45% | ≈2 días (benchmarks reales) | Consolidado en v2.16 (`core/omni_loop.py`) |
| v2.15 | Push summary + capa sensorial | 55% | ≈2 días (tests e2e) | Resumido en `PUSH_SUMMARY_v2.18`; implementación final en v2.16 |
| v2.16 | Omni-Loop Engine reflexivo (3 iteraciones) | 100% | 0h (completo) | Implementado en `core/omni_loop.py` |
| v2.16 | Integración LangGraph multimodal (texto/audio/visión) | 100% | 0h (completo) | `core/graph.py` actualizado |
| v2.16 | Despliegue gRPC Qwen3-VL + audio ONNX | 60% | ≈6h (build + smoke tests) | Código listo; despliegue pendiente |
| v2.16 | Validación KPIs (RAM P99, latencia, auto-corrección) | 40% | ≈8h (benchmarks reales) | Planificada como paso final de release |

> *Los porcentajes y ETAs se derivan de los STATUS oficiales, CHANGELOG y revisión del código actual en la rama `master`.*

## 3. Base técnica
- Núcleo SARAi: Python, LangGraph como orquestador y backend `llama-cpp` para modelos GGUF (SOLAR, LFM2, Qwen). 
- Pila Sentinel: `core/audit.py`, módulos de auditoría web/voz y ganchos de Safe Mode global. 
- Pipeline RAG: `core/web_cache.py`, `core/web_audit.py`, `agents/rag_agent.py` y la cabeza web de TRM. 
- Flujo de release/CI: `.github/workflows/release.yml` construye imágenes multi-arquitectura, SBOM y firma con Cosign.

## 4. Estado del código
- `CHANGELOG.md`: Registra hitos hasta v2.16; sirvió para validar qué pilares están realmente aterrizados en código. 
- `core/audit.py`: Verificación SHA-256 de logs, activación de Safe Mode y alertas vía webhook; depende de `scripts/online_tune.py` y auditorías web/voz. 
- `core/mcp.py`: Meta Control Plane con `MCPCache`, recarga atómica y `route_to_skills`; falta cablear las rutas MoE en producción. 
- `scripts/online_tune.py`: Entrenamiento en sombra placeholder; almacena metadatos pero no actualiza modelos reales. 
- `core/graph.py`: Orquesta texto/audio/visión, integra omni loop y routing hacia RAG; confirma integración modular. 
- Documentos de estado (`STATUS_v2.11.md`, `STATUS_v2.12.md`, `STATUS_v2.16.md`) y módulos de soporte (`core/batch_prioritizer.py`, `core/web_cache.py`, workflow de release) completan el panorama.

## 5. Gestión de incidencias
- Problemas detectados: Desfase entre documentación y código en MoE, batching, logs inmutables, cobertura de Sentinel, pruebas faltantes y attestation ausente. 
- Soluciones aplicadas: No se modificó código en esta sesión; el trabajo se centró en identificar brechas y priorizar acciones correctivas. 
- Notas de depuración: Urge cablear `BatchPrioritizer`, firmar logs de interacción, habilitar tuning real y cerrar el circuito de Sentinel. 
- Lecciones aprendidas: Varias metas se documentaron antes de consolidarse en código; hace falta verificación continua antes de declarar hitos.

## 6. Seguimiento del progreso
- Completado: Entregables v2.0–v2.6, módulos RAG operativos, infraestructura de Safe Mode y la integración principal del omni loop. 
- Parcial: Pilares v2.7, tuning online v2.8, cobertura Sentinel completa y pipeline de attestation. 
- Validado: Dataset de golden queries, auditorías web/voz generando logs firmables y grafo LangGraph enlazando omni + RAG.

## 7. Estado del trabajo en curso
- Foco actual: Elaborar un informe estructurado y en español tras reconfirmar la existencia de componentes omni nativos. 
- Contexto reciente: Últimas lecturas sobre `core/graph.py` (routing del omni loop) y búsqueda de `agents/omni_native.py` para corroborar la implementación de audio/reflexión. 
- Hallazgos en código: Se revisó el `TypedDict` de estado y la lógica de enrutamiento en `core/graph.py`, validando los nodos omni y RAG. 
- Objetivo inmediato: Mantener una fotografía coherente del estado real versus lo anunciado en la documentación.

## 8. Operaciones recientes
- Herramientas invocadas: `file_search("omni_native.py")` (ubicó `/home/noel/SARAi_v2/agents/omni_native.py`), `read_file("/home/noel/SARAi_v2/core/graph.py", 1-400)` (revisión de la orquestación LangGraph) y `read_file("/home/noel/SARAi_v2/tests/golden_queries.jsonl")` (verificación del set de golden queries). 
- Resultados: Confirmación del agente omni nativo, recopilación de rutas y validación del dataset de consultas doradas. 
- Contexto operativo: Estas acciones respaldan la verificación de infraestructura omni y activos necesarios para declarar estado v2.16. 
- Continuidad: Se deja trazada la línea base para abordar los pilares pendientes.

## 9. Plan de continuación

### 9.1 Principios de planificación
- No solapar pistas críticas: cada hito depende del cierre del anterior para evitar retrabajos. 
- Reservar ventanas de validación (benchmarks y pruebas) al final de cada semana. 
- Colaboración cruzada: documentación y code review se programan dentro del mismo hito para no arrastrar deuda.

### 9.2 Estado de ejecución actual (31 Oct 2025)

**Semana 1 - Día 1**: ⚠️ CORRECCIÓN ESTRATÉGICA CRÍTICA

| Ticket | Estado | Tests | LOC | Notas |
|--------|--------|-------|-----|-------|
| T1.0 | ✅ COMPLETADO | 12/12 ✅ | +230 | **Vision Agent (Qwen3-VL-4B)** ⭐ CRÍTICO |
| T1.1 | ❌ CANCELADO | 12/12 | -150 | Skills MoE REDUNDANTE (revertir) |
| T1.2 | ❌ CANCELADO | 11/11 | -110 | Routing MoE REDUNDANTE (revertir) |
| T1.1-NEW | ⏳ PENDIENTE | 0/5 | 0 | Dataset TRM con SOLAR (10K) |
| T1.2-NEW | ⏳ PENDIENTE | 0/8 | 0 | Entrenar TRM-Router (5 heads) |
| T1.3-NEW | ⏳ PENDIENTE | 0/6 | 0 | MCP continuous learning |

**Progreso Semana 1**: 30% real (Vision integrado, Skills MoE a revertir)

**Lección del día**: "Skills son PROMPTS especializados, no LLMs separados. TRM aprende a routear, MCP selecciona config, SOLAR/LFM2 generan con contexto experto."

**Modelos FINALES consolidados** (5 total, NO 11):
1. SOLAR-10.7B (Ollama HTTP) - Expert técnico universal (~200 MB)
2. LFM2-1.2B (GGUF) - Soft + RAG + modulación (~700 MB)
3. EmbeddingGemma-300M - Vectores semánticos (~150 MB, permanente)
4. Qwen2.5-Omni (ONNX) - Audio pipeline (~4.7 GB, v2.18 completo)
5. **Qwen3-VL-4B (GGUF Q6_K)** - **Visión (imagen/video)** (~3.3 GB) ⭐ HOY

**Skills implementados como CONFIGS** (6 total, +0 GB RAM):
1. `programming`: SOLAR + temp=0.2 + prompt experto código
2. `diagnosis`: SOLAR + temp=0.3 + prompt RCA/logs
3. `finance`: SOLAR + temp=0.4 + prompt analista CFA
4. `creative`: LFM2 + temp=0.9 + prompt escritor
5. `reasoning`: SOLAR + temp=0.5 + prompt lógica formal
6. `general`: SOLAR + temp=0.7 + prompt asistente

**Peak RAM**: 9 GB (SOLAR + LFM2 + EmbeddingGemma + Qwen3-VL) < 12 GB ✅



### 9.2 Cronograma consolidado (4 semanas)

| Semana | Hito | Objetivos principales | Dependencias | Entregables |
|--------|------|----------------------|--------------|-------------|
| Semana 1 | Consolidación núcleo (MoE + Prioridades) | 1) Implementar carga dinámica de skills y activar `route_to_skills` en runtime. 2) Integrar `BatchPrioritizer` para fast lane crítico con métricas de latencia. | Estado actual de `core/mcp.py` y `core/batch_prioritizer.py`. | Código en `core/model_pool.py`, `core/graph.py`, tests unitarios MoE/batching, informe de latencia P50/P99. |
| Semana 2 | Sentinel + Tuning | 1) Firmar logs generales con SHA-256/HMAC. 2) Completar `online_tune.py` con entrenamiento real y swap atómico (incluye scheduler y validación Golden Queries). | Semana 1 completada (MoE activo y priorizador estable). | Nuevos módulos de firma en `core/feedback.py`, scripts de verificación, pipeline de tuning nocturno documentado y probado. |
| Semana 3 | Multimodal y RAG hardening | 1) Finalizar despliegue gRPC (Qwen3-VL + audio ONNX) con pruebas E2E. 2) Robustecer RAG (fallback, TTL dinámico, auditoría CLI). 3) Integrar voz en LangGraph con tests end-to-end. | Semanas 1-2 cerradas (para reutilizar logging seguro y priorización). | Smoke tests de contenedores, pruebas de integración voz/texto/web, actualización de manual de despliegue. |
| Semana 4 | Calidad, documentación y release | 1) Benchmarks finales (RAM P99, latencias, auto-corrección). 2) Refresco completo de documentación (README, IMPLEMENTATION, ROADMAP). 3) Pipeline de release con attestation hardware y check de Golden Queries en CI. | Semanas 1-3 cerradas (todo funcional). | Reporte de KPIs, documentación final, workflow CI actualizado, checklist de release firmado. |

### 9.3 Gestión de riesgos
- Riesgo: integración MoE impacta memoria → Mitigación: pruebas progresivas con máximo 2 skills simultáneos antes de ampliar. 
- Riesgo: tuning automático degrade modelos → Mitigación: gating por Golden Queries + rollback automático documentado. 
- Riesgo: retraso en contenedores gRPC → Mitigación: bloquear dos días específicos (Semana 3) sin otras tareas paralelas.

### 9.4 Próximos pasos inmediatos
- Kick-off Semana 1: definir owners y granularizar subtareas en tickets (`MoE-runtime`, `BatchPrioritizer-E2E`, `Latency-Bench`). 
- Preparar checklist de firma de logs y requisitos de tuning (inputs de seguridad) para arrancar Semana 2 sin bloqueos.
