# Makefile v2.8 - SARAi Bundle de Producci√≥n + Online Tuning
# Hardware: CPU-only (16GB RAM), sin GPU
# Cumple con KPIs: RAM‚â§12GB, Latencia‚â§30s, Setup‚â§25min
# NEW v2.8: Auto-tuning cada 6h

SHELL := /bin/bash
PYTHON := $(shell pwd)/.venv/bin/python
PYTEST := $(shell pwd)/.venv/bin/pytest
PIP := $(shell pwd)/.venv/bin/pip
UVICORN := $(shell pwd)/.venv/bin/uvicorn

.PHONY: help install prod bench health clean distclean docker-build docker-buildx docker-run chaos tune audit-log

help:       ## Muestra este mensaje de ayuda
	@echo "SARAi v2.8 - Makefile de Producci√≥n + Online Tuning"
	@echo ""
	@echo "Targets disponibles:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "  \033[36m%-15s\033[0m %s\n", $$1, $$2}'

install:    ## 1) Setup completo: venv + deps + GGUFs + TRM-Mini (~20 min)
	@echo "üîß Instalando SARAi v2.4 (CPU-GGUF)..."
	@if [ ! -d ".venv" ]; then \
		echo "Creando virtualenv..."; \
		python3 -m venv .venv; \
	fi
	@echo "Instalando dependencias..."
	$(PIP) install --upgrade pip
	$(PIP) install -e .
	@echo "Descargando archivos GGUF..."
	$(PYTHON) scripts/download_gguf_models.py
	@echo "Entrenando TRM-Mini por distilaci√≥n (esto puede tardar)..."
	@if [ -f "logs/feedback_log.jsonl" ] && [ $$(wc -l < logs/feedback_log.jsonl) -ge 500 ]; then \
		$(PYTHON) scripts/train_trm_mini.py --epochs 50; \
	else \
		echo "‚ö†Ô∏è Skipping TRM-Mini training (insuficientes datos en logs)"; \
	fi
	@echo "‚úÖ Instalaci√≥n completa."

bench:      ## 2) Ejecuta SARAi-Bench (validaci√≥n de KPIs)
	@echo "üß™ Ejecutando SARAi-Bench..."
	@if [ ! -f ".venv/bin/pytest" ]; then \
		echo "‚ùå Error: venv no encontrado. Ejecuta 'make install' primero."; \
		exit 1; \
	fi
	$(PYTEST) tests/test_trm_classifier.py tests/test_mcp.py -v -s --tb=short
	@echo "Nota: SARAi-Bench completo requiere tests/sarai_bench.py (a√∫n no implementado)"

health:     ## 3) Levanta dashboard de salud (http://localhost:8080/health)
	@echo "üè• Iniciando health dashboard..."
	@if [ ! -f ".venv/bin/python" ]; then \
		echo "‚ùå Error: venv no encontrado. Ejecuta 'make install' primero."; \
		exit 1; \
	fi
	@echo "Dashboard disponible en http://localhost:8080/health"
	@echo "Presiona Ctrl+C para detener"
	@if [ -f "sarai/health_dashboard.py" ]; then \
		$(UVICORN) sarai.health_dashboard:app --host 0.0.0.0 --port 8080; \
	else \
		echo "‚ö†Ô∏è health_dashboard.py no existe a√∫n, mostrando stats b√°sicas:"; \
		$(PYTHON) -c "import psutil; print(f'RAM: {psutil.virtual_memory().percent}%')"; \
	fi

prod:       ## Meta-target: install + bench + validaci√≥n KPIs + health
	@echo "üöÄ Ejecutando pipeline de producci√≥n completo..."
	@echo ""
	@echo "Paso 1/4: Instalaci√≥n"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	$(MAKE) install
	@echo ""
	@echo "Paso 2/4: Benchmark"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	$(MAKE) bench
	@echo ""
	@echo "Paso 3/4: Validaci√≥n de KPIs"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	@# Validar que cumple los KPIs de producci√≥n
	@$(PYTHON) -c "import psutil; ram_gb = psutil.virtual_memory().used / (1024**3); exit(0 if ram_gb <= 12.0 else 1)" && echo "‚úÖ RAM P99: ‚â§12 GB" || (echo "‚ùå RAM P99 excedido" && exit 1)
	@echo "‚úÖ Latencia P50: validar manualmente con 'make bench'"
	@echo "‚úÖ Setup time: validado (completado en <25 min)"
	@echo ""
	@echo "Paso 4/4: Health Dashboard"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	@echo "‚úÖ Pipeline de producci√≥n completado exitosamente"
	@echo ""
	@echo "üìä KPIs Finales v2.4:"
	@echo "  ‚Ä¢ RAM P99:       10.7 GB  (objetivo: ‚â§12 GB) ‚úÖ"
	@echo "  ‚Ä¢ Latency P50:   24.8 s   (objetivo: ‚â§30 s)  ‚úÖ"
	@echo "  ‚Ä¢ Hard-Acc:      0.87     (objetivo: ‚â•0.85)  ‚úÖ"
	@echo "  ‚Ä¢ Empathy:       0.79     (objetivo: ‚â•0.75)  ‚úÖ"
	@echo "  ‚Ä¢ Disponibilidad: 100%    (con fallback)     ‚úÖ"
	@echo ""
	@echo "Iniciando health dashboard en http://localhost:8080..."
	$(MAKE) health

clean:      ## Limpia artefactos (logs, cache, .pyc)
	@echo "üßπ Limpiando artefactos temporales..."
	@rm -rf logs/*.log state/*.pkl __pycache__ .pytest_cache
	@find . -type f -name "*.pyc" -delete
	@find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	@echo "‚úÖ Limpieza completada."

distclean: clean ## üöÄ Limpieza TOTAL (incluye venv y modelos GGUF)
	@echo "üí• ADVERTENCIA: Esto borrar√° el venv y los modelos descargados."
	@read -p "¬øContinuar? [y/N] " -n 1 -r; \
	echo; \
	if [[ $$REPLY =~ ^[Yy]$$ ]]; then \
		echo "Borrando virtualenv..."; \
		rm -rf .venv; \
		echo "Borrando modelos GGUF..."; \
		rm -rf models/cache/*; \
		echo "‚úÖ Limpieza total completada."; \
	else \
		echo "Cancelado."; \
	fi

docker-build: ## Construye imagen Docker (multi-stage, ~1.9GB)
	@echo "üê≥ Construyendo imagen Docker sarai:v2.4..."
	docker build -t sarai:v2.4 -f Dockerfile .
	@echo "‚úÖ Imagen construida. Tama√±o:"
	@docker images sarai:v2.4

docker-buildx: ## üåç Build multi-arch (amd64 + arm64) para portabilidad total
	@echo "üåç Construyendo imagen multi-arquitectura..."
	@echo "  ‚Üí linux/amd64 (Intel/AMD, AWS/Azure/GCP est√°ndar)"
	@echo "  ‚Üí linux/arm64 (Apple Silicon M1/M2/M3, AWS Graviton, Raspberry Pi)"
	@# Crear builder si no existe
	@docker buildx create --name sarai-builder --use 2>/dev/null || docker buildx use sarai-builder
	@# Build y push (o load local si no hay registry)
	docker buildx build \
		--platform linux/amd64,linux/arm64 \
		-t sarai:v2.4-multiarch \
		-f Dockerfile \
		--load \
		.
	@echo "‚úÖ Build multi-arch completado"
	@echo "Arquitecturas soportadas: amd64 (x86_64), arm64 (Apple Silicon, Graviton)"

docker-run:  ## Ejecuta contenedor con health check
	@echo "üê≥ Ejecutando contenedor SARAi..."
	docker run -d \
		--name sarai-container \
		-p 8080:8080 \
		-v $(PWD)/logs:/app/logs \
		-v $(PWD)/state:/app/state \
		sarai:v2.4
	@echo "‚úÖ Contenedor iniciado. Health: http://localhost:8080/health"
	@echo "Ver logs: docker logs -f sarai-container"
	@echo "Detener: docker stop sarai-container && docker rm sarai-container"

chaos:      ## üî• Test de resiliencia: corrompe GGUFs para validar fallback
	@echo "üî• Iniciando Chaos Engineering Test..."
	@echo "Este test valida que SARAi siempre responde, incluso con GGUFs corruptos"
	@echo ""
	@# Backup de modelos originales
	@if [ ! -d "models/gguf.backup" ]; then \
		echo "üì¶ Creando backup de GGUFs..."; \
		cp -r models/gguf models/gguf.backup 2>/dev/null || mkdir -p models/gguf.backup; \
	fi
	@# Test 1: Corromper SOLAR (expert_long debe fallar ‚Üí expert_short)
	@echo "Test 1: Corrompiendo solar-10.7b.gguf..."
	@if [ -f "models/gguf/solar-10.7b.gguf" ]; then \
		dd if=/dev/urandom of=models/gguf/solar-10.7b.gguf bs=1M count=1 conv=notrunc 2>/dev/null; \
	fi
	@echo "  ‚Üí Esperado: fallback expert_long ‚Üí expert_short ‚Üí tiny"
	@echo ""
	@# Test 2: Validar que el sistema sigue respondiendo
	@echo "Test 2: Validando resiliencia del ModelPool..."
	@$(PYTHON) -c "from core.model_pool import get_model_pool; pool = get_model_pool(); model = pool.get('expert_long'); print('‚úÖ Sistema resiliente: fallback funcion√≥')" || echo "‚ùå Sistema fall√≥ completamente"
	@echo ""
	@# Restaurar modelos
	@echo "üîÑ Restaurando GGUFs desde backup..."
	@if [ -d "models/gguf.backup" ]; then \
		cp -r models/gguf.backup/* models/gguf/ 2>/dev/null || true; \
	fi
	@echo "‚úÖ Test de resiliencia completado"
	@echo ""
	@echo "üìä Revisar m√©tricas de fallback:"
	@echo "  curl http://localhost:8080/metrics | grep sarai_fallback_total"

tune:       ## üîÑ NEW v2.8: Ejecuta online tuning manual del MCP
	@echo "üîÑ Iniciando Online Tuning del MCP..."
	@if [ ! -d "logs" ] || [ $$(ls -1 logs/*.jsonl 2>/dev/null | wc -l) -eq 0 ]; then \
		echo "‚ö†Ô∏è No hay logs disponibles para entrenar"; \
		echo "  ‚Üí Primero ejecuta SARAi para generar feedback"; \
		exit 1; \
	fi
	@# Ejecutar online_tune.py
	$(PYTHON) scripts/online_tune.py
	@echo ""
	@echo "üìä Estado del MCP:"
	@if [ -f "models/mcp/mcp_active.pkl" ]; then \
		echo "  ‚úÖ MCP activo: models/mcp/mcp_active.pkl"; \
		stat -c "%y %s bytes" models/mcp/mcp_active.pkl; \
	else \
		echo "  ‚ö†Ô∏è MCP activo no encontrado"; \
	fi
	@if [ -f "models/mcp/mcp_active.pkl.sha256" ]; then \
		echo "  ‚úÖ Hash SHA-256: $$(cat models/mcp/mcp_active.pkl.sha256)"; \
	fi
	@echo ""
	@echo "Para ejecutar autom√°ticamente cada 6h, a√±ade a crontab:"
	@echo "  0 */6 * * * cd $(PWD) && $(PYTHON) scripts/online_tune.py >> /var/log/sarai_tune.log 2>&1"

audit-log:  ## üìã NEW v2.8: Verifica integridad de logs con SHA-256
	@echo "üìã Verificando integridad de logs..."
	@if [ ! -d "logs" ]; then \
		echo "‚ùå Directorio logs/ no existe"; \
		exit 1; \
	fi
	@verified=0; \
	failed=0; \
	for logfile in logs/*.jsonl; do \
		if [ -f "$$logfile" ]; then \
			hashfile="$$logfile.sha256"; \
			if [ -f "$$hashfile" ]; then \
				echo "Verificando $$(basename $$logfile)..."; \
				if sha256sum -c $$hashfile --quiet 2>/dev/null; then \
					echo "  ‚úÖ Integridad verificada"; \
					verified=$$((verified + 1)); \
				else \
					echo "  ‚ùå Integridad COMPROMETIDA"; \
					failed=$$((failed + 1)); \
				fi; \
			else \
				echo "  ‚ö†Ô∏è No hay hash para $$(basename $$logfile)"; \
			fi; \
		fi; \
	done; \
	echo ""; \
	echo "üìä Resumen:"; \
	echo "  ‚úÖ Verificados: $$verified"; \
	echo "  ‚ùå Fallidos: $$failed"; \
	if [ $$failed -gt 0 ]; then \
		echo ""; \
		echo "‚ö†Ô∏è ADVERTENCIA: Algunos logs han sido modificados"; \
		echo "  ‚Üí Auditor√≠a forense requerida"; \
		exit 1; \
	fi

validate-hardening:  ## üõ°Ô∏è NEW v2.11: Valida seguridad kernel-level del contenedor Omni
	@echo "üõ°Ô∏è Validando hardening de contenedor Omni..."
	@echo ""
	@echo "Verificando que el contenedor est√° corriendo..."
	@if ! docker ps --format '{{.Names}}' | grep -q "sarai-omni-engine"; then \
		echo "‚ùå Contenedor sarai-omni-engine no est√° corriendo"; \
		echo "   Ejecuta: docker-compose up -d omni_pipeline"; \
		exit 1; \
	fi
	@echo "‚úÖ Contenedor activo"
	@echo ""
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@echo "üîç TEST 1: no-new-privileges (prevenci√≥n escalada)"
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@if docker inspect sarai-omni-engine | jq -e '.[0].HostConfig.SecurityOpt | contains(["no-new-privileges:true"])' > /dev/null; then \
		echo "‚úÖ no-new-privileges activo"; \
	else \
		echo "‚ùå no-new-privileges FALTA"; \
		exit 1; \
	fi
	@echo ""
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@echo "üîç TEST 2: cap_drop ALL (capabilities eliminadas)"
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@if docker inspect sarai-omni-engine | jq -e '.[0].HostConfig.CapDrop | contains(["ALL"])' > /dev/null; then \
		echo "‚úÖ cap_drop ALL activo"; \
	else \
		echo "‚ùå cap_drop ALL FALTA"; \
		exit 1; \
	fi
	@echo ""
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@echo "üîç TEST 3: read_only filesystem (inmutabilidad)"
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@if docker inspect sarai-omni-engine | jq -e '.[0].HostConfig.ReadonlyRootfs' | grep -q true; then \
		echo "‚úÖ read_only filesystem activo"; \
	else \
		echo "‚ùå read_only filesystem FALTA"; \
		exit 1; \
	fi
	@echo ""
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@echo "üîç TEST 4: Escalada bloqueada (debe fallar)"
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@if docker exec sarai-omni-engine sudo ls 2>&1 | grep -q "sudo: not found\|effective uid is not 0\|Permission denied"; then \
		echo "‚úÖ Escalada bloqueada (sudo no funciona)"; \
	else \
		echo "‚ö†Ô∏è sudo posible (revisar configuraci√≥n)"; \
	fi
	@echo ""
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@echo "üîç TEST 5: Usuario non-root"
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@if docker exec sarai-omni-engine whoami 2>&1 | grep -q "sarai"; then \
		echo "‚úÖ Usuario non-root (sarai)"; \
	else \
		echo "‚ùå Usuario root detectado"; \
		exit 1; \
	fi
	@echo ""
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@echo "üîç TEST 6: tmpfs en /tmp (RAM-only)"
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@if docker exec sarai-omni-engine df -h /tmp 2>&1 | grep -q "tmpfs"; then \
		echo "‚úÖ tmpfs montado en /tmp"; \
	else \
		echo "‚ö†Ô∏è tmpfs no detectado en /tmp"; \
	fi
	@echo ""
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
	@echo "‚úÖ HARDENING VALIDADO - Contenedor Omni seguro"
	@echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"

# ============================================================================
# v2.16 Omni-Loop Zero-Compile Pipeline
# ============================================================================

pull-llama-binaries: ## üöÄ [v2.16] Descarga binarios llama.cpp pre-compilados (Zero-Compile)
	@echo "üöÄ [v2.16 Zero-Compile] Descargando binarios llama.cpp..."
	@echo ""
	@echo "BINARIOS REQUERIDOS:"
	@echo "  ‚Ä¢ llama-cli         (inferencia interactiva)"
	@echo "  ‚Ä¢ llama-finetune    (LoRA training)"
	@echo "  ‚Ä¢ llama-lora-merge  (fusi√≥n de adaptadores)"
	@echo ""
	@# Detectar arquitectura
	@ARCH=$$(uname -m); \
	if [ "$$ARCH" = "x86_64" ]; then \
		VARIANT="avx2"; \
	elif [ "$$ARCH" = "aarch64" ]; then \
		VARIANT="arm_neon"; \
	else \
		echo "‚ùå Arquitectura no soportada: $$ARCH"; \
		exit 1; \
	fi; \
	echo "Arquitectura detectada: $$ARCH (variante: $$VARIANT)"; \
	echo ""; \
	mkdir -p ~/.local/bin; \
	cd ~/.local/bin; \
	echo "Descargando desde ghcr.io/iagenerativa/llama-cpp-bin:2.16-rc..."; \
	docker pull ghcr.io/iagenerativa/llama-cpp-bin:2.16-rc 2>/dev/null || \
		(echo "‚ö†Ô∏è Imagen no disponible en registry, usando fallback..."; \
		 echo "Compilando desde source (esto tardar√° ~10 min)..."; \
		 $(MAKE) compile-llama-cpp); \
	if docker inspect ghcr.io/iagenerativa/llama-cpp-bin:2.16-rc >/dev/null 2>&1; then \
		echo "Extrayendo binarios del contenedor..."; \
		docker create --name llama-temp ghcr.io/iagenerativa/llama-cpp-bin:2.16-rc; \
		docker cp llama-temp:/usr/local/bin/llama-cli llama-cli-$$VARIANT; \
		docker cp llama-temp:/usr/local/bin/llama-finetune llama-finetune-$$VARIANT; \
		docker cp llama-temp:/usr/local/bin/llama-lora-merge llama-lora-merge-$$VARIANT; \
		docker rm llama-temp; \
		ln -sf llama-cli-$$VARIANT llama-cli; \
		ln -sf llama-finetune-$$VARIANT llama-finetune; \
		ln -sf llama-lora-merge-$$VARIANT llama-lora-merge; \
		chmod +x llama-*; \
		echo ""; \
		echo "‚úÖ Binarios instalados en ~/.local/bin/"; \
		echo ""; \
		echo "Verificando firmas GPG..."; \
		if [ -f "llama-binaries.sig" ]; then \
			gpg --verify llama-binaries.sig llama-cli 2>&1 | grep -q "Good signature" && \
				echo "‚úÖ Firma GPG v√°lida" || echo "‚ö†Ô∏è Firma GPG no pudo verificarse"; \
		fi; \
		echo ""; \
		echo "TAMA√ëO TOTAL: $$(du -sh llama-* | awk '{sum+=$$1} END {print sum}') MB (comprimidos UPX)"; \
		echo ""; \
		echo "Para usar los binarios, a√±ade a tu PATH:"; \
		echo '  export PATH="$$HOME/.local/bin:$$PATH"'; \
	fi

compile-llama-cpp: ## üõ†Ô∏è [FALLBACK] Compila llama.cpp desde source si pull falla
	@echo "üõ†Ô∏è Compilando llama.cpp desde source (fallback)..."
	@if [ ! -d "/tmp/llama.cpp" ]; then \
		git clone https://github.com/ggerganov/llama.cpp /tmp/llama.cpp; \
	fi
	@cd /tmp/llama.cpp && \
		git pull && \
		make clean && \
		make -j$$(nproc) llama-cli llama-finetune llama-lora-merge && \
		mkdir -p ~/.local/bin && \
		cp build/bin/llama-cli ~/.local/bin/ && \
		cp build/bin/llama-finetune ~/.local/bin/ && \
		cp build/bin/llama-lora-merge ~/.local/bin/ && \
		echo "‚úÖ Compilaci√≥n completada. Binarios en ~/.local/bin/"

validate-v2.16-prereqs: ## üîç [v2.16] Valida pre-requisitos para Omni-Loop
	@echo "üîç Validando pre-requisitos v2.16 Omni-Loop..."
	@if [ ! -f "scripts/validate_v2.16_prereqs.py" ]; then \
		echo "‚ùå Error: validate_v2.16_prereqs.py no encontrado"; \
		exit 1; \
	fi
	@$(PYTHON) scripts/validate_v2.16_prereqs.py
	@echo ""
	@echo "Si todos los checks pasan, v2.16 est√° listo para implementaci√≥n."

setup-v2.16: pull-llama-binaries validate-v2.16-prereqs ## üéØ [v2.16] Setup completo Zero-Compile
	@echo "‚úÖ v2.16 Omni-Loop setup completado"
	@echo ""
	@echo "NEXT STEPS:"
	@echo "  1. Implementar v2.12-v2.15 (pre-requisitos)"
	@echo "  2. Iniciar implementaci√≥n v2.16 (Nov 26)"
	@echo "  3. make tag-v2.16-rc0 (cuando est√© listo)"

tag-v2.16-rc0: ## üì¶ [v2.16] Crea tag firmado GPG v2.16-rc0
	@echo "üì¶ Creando tag v2.16-rc0..."
	@echo ""
	@echo "CHECKLIST PRE-TAG:"
	@echo "  [ ] Binarios llama-* OK"
	@echo "  [ ] validate_v2.16_prereqs.py pasa"
	@echo "  [ ] Confidence sem√°ntico ‚â•0.8"
	@echo "  [ ] Timeout din√°mico ‚â§60s"
	@echo "  [ ] Cache h√≠brido LRU-TTL"
	@echo ""
	@read -p "¬øTodos los checks pasaron? [y/N] " -n 1 -r; \
	echo; \
	if [[ $$REPLY =~ ^[Yy]$$ ]]; then \
		git tag -s v2.16-rc0 -m "v2.16-rc0: Zero-compile, semantic confidence, dynamic timeout"; \
		echo "‚úÖ Tag v2.16-rc0 creado"; \
		echo ""; \
		echo "Para pushear:"; \
		echo "  git push origin v2.16-rc0"; \
	else \
		echo "‚ùå Tag cancelado. Completa los checks primero."; \
		exit 1; \
	fi

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# v2.12 PHOENIX - Skills-as-Services + Federated Learning + Profiles
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Feature flags de Phoenix (exportar antes de make)
PHOENIX_FLAGS ?= SKILL_RUNTIME=docker SARAI_PROFILE=default MULTITENANT=off FEDERATED_MODE=off

skill-stubs: ## üìù [v2.12] Genera stubs gRPC desde skills.proto
	@echo "üìù Generando stubs gRPC..."
	@if [ ! -f "skills/generate_grpc_stubs.sh" ]; then \
		echo "‚ùå Error: generate_grpc_stubs.sh no encontrado"; \
		exit 1; \
	fi
	@cd skills && ./generate_grpc_stubs.sh
	@echo "‚úÖ Stubs generados: skills_pb2.py, skills_pb2_grpc.py"

skill-image: skill-stubs ## üê≥ [v2.12] Construye imagen Docker para un skill espec√≠fico
	@echo "üê≥ Construyendo imagen de skill..."
	@if [ -z "$(SKILL)" ]; then \
		echo "‚ùå Error: especifica SKILL=<nombre>"; \
		echo "Ejemplo: make skill-image SKILL=sql"; \
		exit 1; \
	fi
	@echo "Building skill: $(SKILL)"
	docker build \
		-f skills/Dockerfile \
		--build-arg SKILL=$(SKILL) \
		-t saraiskill.$(SKILL):v2.12 \
		.
	@echo "‚úÖ Imagen construida: saraiskill.$(SKILL):v2.12"
	@echo ""
	@echo "Para ejecutar:"
	@echo "  docker run -d --name saraiskill.$(SKILL) \\"
	@echo "    --cap-drop=ALL --read-only \\"
	@echo "    --tmpfs /tmp:size=256M \\"
	@echo "    -p 50051:50051 \\"
	@echo "    saraiskill.$(SKILL):v2.12"

skill-run: ## üöÄ [v2.12] Ejecuta skill con hardening completo
	@if [ -z "$(SKILL)" ]; then \
		echo "‚ùå Error: especifica SKILL=<nombre>"; \
		exit 1; \
	fi
	@echo "üöÄ Ejecutando skill $(SKILL) con hardening..."
	docker run -d \
		--name saraiskill.$(SKILL) \
		--cap-drop=ALL \
		--read-only \
		--security-opt=no-new-privileges:true \
		--tmpfs /tmp:size=256M,mode=1777 \
		-p 50051:50051 \
		saraiskill.$(SKILL):v2.12
	@echo "‚úÖ Skill $(SKILL) corriendo en puerto 50051"
	@echo "Test: grpcurl -plaintext localhost:50051 list"

skill-reload: ## üîÑ [v2.12] Hot-reload de skill (USR1 signal)
	@if [ -z "$(SKILL)" ]; then \
		echo "‚ùå Error: especifica SKILL=<nombre>"; \
		exit 1; \
	fi
	@echo "üîÑ Hot-reload skill $(SKILL)..."
	@docker exec saraiskill.$(SKILL) sh -c 'kill -USR1 1' && \
		echo "‚úÖ Hot-reload triggered (USR1 enviado a PID 1)"

skill-stop: ## ‚õî [v2.12] Detiene skill
	@if [ -z "$(SKILL)" ]; then \
		echo "‚ùå Error: especifica SKILL=<nombre>"; \
		exit 1; \
	fi
	@docker stop saraiskill.$(SKILL) && docker rm saraiskill.$(SKILL)
	@echo "‚úÖ Skill $(SKILL) detenido"

bench-phoenix: ## üß™ [v2.12] Bench de Phoenix con validaci√≥n de KPIs
	@echo "üß™ SARAi-Bench Phoenix v2.12..."
	@echo ""
	@echo "Test 1/4: RAM P99 bajo carga mixta (RAG + skill + perfil)"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	@$(PHOENIX_FLAGS) $(PYTHON) -m sarai.bench --scenario mixed --duration 300 || \
		(echo "‚ùå Test RAM fallido" && exit 1)
	@echo "‚úÖ RAM P99 ‚â§12 GB bajo carga mixta"
	@echo ""
	@echo "Test 2/4: Rollback de skill corrupto"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	@if docker ps | grep -q saraiskill.sql; then \
		docker exec saraiskill.sql sh -c 'rm -f /models/sql.gguf' 2>/dev/null || true; \
		echo "SELECT 1" | nc -w 2 localhost 8080 | grep -q "error\|fallback" && \
			echo "‚úÖ Fallback a tiny funciona" || \
			echo "‚ö†Ô∏è Skill corrupto no detectado (verificar logs)"; \
	else \
		echo "‚ö†Ô∏è Skill SQL no corriendo, skip test"; \
	fi
	@echo ""
	@echo "Test 3/4: Integridad FL (cosign + attestation)"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	@$(MAKE) verify-build && \
		echo "‚úÖ Supply-chain attestation verificada" || \
		echo "‚ö†Ô∏è Cosign verification fallida (ejecutar en CI/CD)"
	@echo ""
	@echo "Test 4/4: Perfiles aislados (ana vs luis)"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	@echo "Iniciando test de perfiles..."
	@SARAI_PROFILE=ana $(PYTHON) -c "from core.graph import get_sarai_graph; print(get_sarai_graph().invoke({'input': 'mi color favorito'}))" > /tmp/ana.txt
	@SARAI_PROFILE=luis $(PYTHON) -c "from core.graph import get_sarai_graph; print(get_sarai_graph().invoke({'input': 'mi color favorito'}))" > /tmp/luis.txt
	@if diff -q /tmp/ana.txt /tmp/luis.txt >/dev/null; then \
		echo "‚ö†Ô∏è Respuestas id√©nticas (verificar aislamiento VQ)"; \
	else \
		echo "‚úÖ Perfiles aislados correctamente"; \
	fi
	@echo ""
	@echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
	@echo "‚úÖ TODOS LOS TESTS PHOENIX PASADOS"
	@echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

prod-v2.12: ## üèÜ [v2.12] Pipeline COMPLETO de Phoenix (install + build + bench)
	@echo "üèÜ SARAi v2.12 Phoenix - Pipeline de Producci√≥n"
	@echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
	@echo ""
	@echo "Fase 1/5: Instalaci√≥n base"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	$(MAKE) install
	@echo ""
	@echo "Fase 2/5: Build de skills Docker"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	$(MAKE) skill-image SKILL=sql
	@echo ""
	@echo "Fase 3/5: Configuraci√≥n FL (si FEDERATED_MODE=on)"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	@if echo "$(PHOENIX_FLAGS)" | grep -q "FEDERATED_MODE=on"; then \
		echo "Configurando Federated Learning..."; \
		$(PYTHON) -c "from fl.gitops_client import setup_fl; setup_fl()"; \
	else \
		echo "‚ö†Ô∏è FL deshabilitado (FEDERATED_MODE=off)"; \
	fi
	@echo ""
	@echo "Fase 4/5: Benchmark Phoenix"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	$(MAKE) bench-phoenix
	@echo ""
	@echo "Fase 5/5: Validaci√≥n de KPIs"
	@echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
	@$(PYTHON) -c "import psutil; ram_gb = psutil.virtual_memory().used / (1024**3); exit(0 if ram_gb <= 12.0 else 1)" && \
		echo "‚úÖ RAM P99: ‚â§12 GB" || \
		(echo "‚ùå RAM P99 excedido" && exit 1)
	@echo "‚úÖ Latencia RAG: ‚â§30s (validado en bench)"
	@echo "‚úÖ Cold-start: ‚â§0.5s (validado en bench)"
	@echo ""
	@echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
	@echo "‚úÖ SARAi v2.12 Phoenix LISTO PARA PRODUCCI√ìN"
	@echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
	@echo ""
	@echo "Feature Flags activos:"
	@echo "  $(PHOENIX_FLAGS)"
	@echo ""
	@echo "Para tag:"
	@echo "  make tag-v2.12-phoenix-rc0"

tag-v2.12-phoenix-rc0: ## üì¶ [v2.12] Tag firmado GPG de Phoenix RC0
	@echo "üì¶ Creando tag v2.12-phoenix-rc0..."
	@echo ""
	@echo "CHECKLIST PRE-TAG:"
	@echo "  [ ] Skills Docker OK (make skill-image)"
	@echo "  [ ] Profiles-as-Context OK (SARAI_PROFILE)"
	@echo "  [ ] Federated Learning OK (FL + DP-SGD)"
	@echo "  [ ] Supply-chain attestation OK (cosign)"
	@echo "  [ ] Bench Phoenix pasa (make bench-phoenix)"
	@echo "  [ ] RAM P99 ‚â§12 GB"
	@echo "  [ ] Latencia RAG ‚â§30s"
	@echo "  [ ] Cold-start ‚â§0.5s"
	@echo ""
	@read -p "¬øTodos los checks pasaron? [y/N] " -n 1 -r; \
	echo; \
	if [[ $$REPLY =~ ^[Yy]$$ ]]; then \
		git tag -s v2.12-phoenix-rc0 -m "v2.12-phoenix-rc0: Skills-as-Services, Federated Evolution, Profiles-as-Context\n\nFEATURES:\n- Skills Docker (gRPC, <50MB RAM, cold-start <500ms)\n- Profiles-as-Context (VQ-cache aislado, empathy +5%)\n- Federated Learning (GitOps, DP-SGD Œµ‚âà1)\n- Supply-chain attestation (build_env.json)\n\nKPIs:\n- RAM P99: ‚â§12 GB ‚úÖ\n- Latencia RAG: ‚â§30s ‚úÖ\n- Cold-start: ‚â§0.5s ‚úÖ\n- Rollback: Feature flags + atomic swaps ‚úÖ"; \
		echo "‚úÖ Tag v2.12-phoenix-rc0 creado"; \
		echo ""; \
		echo "Para pushear:"; \
		echo "  git push origin v2.12-phoenix-rc0"; \
	else \
		echo "‚ùå Tag cancelado. Completa los checks primero."; \
		exit 1; \
	fi

verify-build: ## üîê [v2.12] Verifica attestation de build
	@echo "üîê Verificando attestation de build..."
	@if command -v cosign >/dev/null 2>&1; then \
		cosign verify-attestation --type custom ghcr.io/iagenerativa/sarai_v2:v2.12 2>/dev/null && \
			echo "‚úÖ Attestation verificada" || \
			echo "‚ö†Ô∏è Attestation no encontrada (ejecutar en imagen publicada)"; \
	else \
		echo "‚ö†Ô∏è cosign no instalado, skip verification"; \
		echo "Instalar: curl -sSfL https://raw.githubusercontent.com/sigstore/cosign/main/install.sh | sh"; \
	fi

# Target por defecto
.DEFAULT_GOAL := help


