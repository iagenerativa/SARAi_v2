# SARAi v2.17 - Plan de Implementaci√≥n Full-Duplex

## üìÖ Estado Actual: 30 de octubre de 2025

---

## ‚úÖ **COMPLETADO** - Capa 1: I/O Full-Duplex

### Componentes Implementados:

#### **Canal IN** ‚úÖ

1. **`vosk_streaming.py`** ‚úÖ
   - Vosk STT en modo streaming (chunks de 100ms)
   - Clase `VoskStreamingSession` con buffer inteligente
   - Detecci√≥n de fin de frase por silencio (500ms)
   - Test standalone funcional

2. **`bert_embedder.py`** ‚úÖ (reutilizado, archivo existente)
   - BERT-es embeddings (768-dim)
   - Similitud sem√°ntica
   - Batch encoding

3. **`lora_router.py`** ‚úÖ
   - Router con LoRA (Low-Rank Adaptation)
   - Clasificaci√≥n: TRM / LLM / Traducir
   - ~2M params entrenables (LoRA adapters)
   - Sistema de entrenamiento incluido
   - Save/Load funcional

4. **`input_thread.py`** ‚úÖ
   - Orquestador del Canal IN
   - 3 threads:
     - Audio Capture (arecord + VAD)
     - STT Processing (Vosk streaming)
     - Routing (BERT + LoRA)
   - Colas thread-safe
   - Estad√≠sticas en tiempo real

#### **Canal OUT** ‚úÖ

1. **`output_thread.py`** ‚úÖ
   - Thread 1: Response Generation (TRM/LLM/NLLB)
   - Thread 2: TTS Streaming (Piper)
   - Thread 3: Audio Playback (aplay)
   - TRM Cache con respuestas comunes (< 50ms)
   - Integraci√≥n LFM2 para generaci√≥n completa
   - Espera inteligente (no interrumpe usuario)

2. **`orchestrator.py`** ‚úÖ
   - Coordina Canal IN + Canal OUT
   - Cola compartida de decisiones
   - Flag compartido (usuario hablando)
   - Estad√≠sticas unificadas
   - Modo interactivo completo

### Test de Capa 1:
```bash
# Test componentes individuales
python3 -m core.layer1_io.vosk_streaming    # ‚úÖ Streaming STT
python3 -m core.layer1_io.lora_router       # ‚úÖ Router con datos sint√©ticos
python3 -m core.layer1_io.input_thread      # ‚úÖ Canal IN
python3 -m core.layer1_io.output_thread     # ‚úÖ Canal OUT
python3 -m core.layer1_io.orchestrator      # ‚úÖ Orquestador

# Test integraci√≥n completa
python3 tests/test_layer1_fullduplex.py     # ‚úÖ Full-Duplex E2E
```

### Archivos Creados (Capa 1):
```
core/layer1_io/
‚îú‚îÄ‚îÄ __init__.py                 ‚úÖ (actualizado)
‚îú‚îÄ‚îÄ vosk_streaming.py           ‚úÖ (323 l√≠neas)
‚îú‚îÄ‚îÄ lora_router.py              ‚úÖ (384 l√≠neas)
‚îú‚îÄ‚îÄ input_thread.py             ‚úÖ (267 l√≠neas)
‚îú‚îÄ‚îÄ output_thread.py            ‚úÖ (386 l√≠neas)
‚îî‚îÄ‚îÄ orchestrator.py             ‚úÖ (241 l√≠neas)

tests/
‚îî‚îÄ‚îÄ test_layer1_fullduplex.py   ‚úÖ (118 l√≠neas)

Total: ~1,719 l√≠neas de c√≥digo productivo
```

---

## ‚è≥ **PENDIENTE** - Capa 2: Coherencia Persistente (RAG)

### Componentes a Crear:

1. **`embedding_gemma.py`** ‚è≥
   - Wrapper para EmbeddingGemma 2B
   - Embeddings de 2048-dim
   - Lazy loading

2. **`qdrant_store.py`** ‚è≥
   - Cliente Qdrant local
   - Indexaci√≥n de turnos conversacionales
   - Retrieval K=5 turnos relevantes

3. **`conversation_rag.py`** ‚è≥
   - RAG conversacional completo
   - Manejo de interrupciones
   - Reconstrucci√≥n de contexto

### Test Capa 2:
```python
# Test indexaci√≥n
rag = ConversationRAG()
rag.index_turn(
    user="¬øQu√© es la IA?",
    assistant="La IA es..."
)

# Test recuperaci√≥n
context = rag.retrieve_context("sobre lo que dijiste de IA", k=3)
# ‚Üí Retorna turno anterior con embeddings similares
```

---

## ‚è≥ **PENDIENTE** - Capa 3: Gesti√≥n de Fluidez (Fillers)

### Componentes a Crear:

1. **`filler_manager.py`** ‚è≥
   - Detecta latencia > 800ms
   - Reproduce coletillas pregrabadas
   - Estrategia adaptativa (no spam de fillers)

2. **`latency_detector.py`** ‚è≥
   - Monitorea tiempo desde √∫ltima palabra
   - Predice latencia LLM
   - Trigger de fillers

3. **`generate_fillers.py`** ‚è≥
   - Script para generar coletillas con Piper TTS
   - "Mmm...", "D√©jame pensar...", "Interesante..."
   - Guardar en `assets/fillers/*.wav`

4. **`assets/fillers/fillers.yaml`** ‚è≥
   - Metadata de cada filler
   - Duraci√≥n, contexto de uso, gap m√≠nimo

### Fillers a Generar:
```yaml
fillers:
  - id: hmm_01
    file: hmm_01.wav
    text: "Mmm..."
    duration_ms: 400
    usage: "Latencia 800-1200ms"
  
  - id: thinking_01
    file: thinking_01.wav
    text: "D√©jame pensar..."
    duration_ms: 800
    usage: "Latencia 1200-2000ms"
  
  - id: interesting_01
    file: interesting_01.wav
    text: "Interesante, necesito considerar..."
    duration_ms: 1200
    usage: "Latencia > 2000ms"
```

---

## ‚è≥ **PENDIENTE** - Capa 4: Orquestaci√≥n Din√°mica (LoRA Scheduler)

### Componentes a Crear:

1. **`lora_scheduler.py`** ‚è≥
   - LoRA para ajuste din√°mico de recursos
   - Prioriza threads seg√∫n contexto:
     - Usuario hablando ‚Üí STT priority
     - Usuario callado + LLM ‚Üí LLM priority
     - Respuesta lista ‚Üí TTS priority
   - Ajusta `n_threads` de LFM2 din√°micamente

2. **`resource_monitor.py`** ‚è≥
   - Monitorea CPU, RAM, tama√±o de colas
   - Detecta cuellos de botella
   - Feed al LoRA Scheduler

### Pol√≠ticas de Priorizaci√≥n:
```python
# Ejemplo de ajuste din√°mico
context = {
    "input_queue_size": 3,      # Usuario hablando mucho
    "llm_queue_size": 0,        # LLM idle
    "cpu_usage": 0.85,          # CPU alta
    "user_speaking": True
}

# LoRA Scheduler decide:
adjustments = {
    "boost_stt": True,          # Prioridad a STT
    "llm_n_threads": 2,         # Reduce LLM temporalmente
    "tts_pause": True           # Pausa TTS (usuario hablando)
}
```

---

## ‚è≥ **PENDIENTE** - Integraci√≥n Final

### Orquestador Maestro:

**`core/orchestrator_fullduplex.py`** ‚è≥
- Coordina las 4 capas
- Gestiona ciclo de vida de threads
- M√©tricas globales
- Health monitoring

### Test E2E:

**`tests/test_fullduplex.py`** ‚è≥
```python
# Test conversaci√≥n completa
orchestrator = FullDuplexOrchestrator()
orchestrator.start()

# Usuario: "Hola, ¬øc√≥mo est√°s?"
# ‚Üí Canal IN ‚Üí Router: TRM
# ‚Üí Canal OUT ‚Üí TRM cache: "¬°Hola! Muy bien, gracias."
# ‚Üí Latencia total: ~1.2s

# Usuario: "Expl√≠came la relatividad"
# ‚Üí Canal IN ‚Üí Router: LLM
# ‚Üí Capa 3 ‚Üí Filler: "Mmm, d√©jame pensar..."
# ‚Üí Canal OUT ‚Üí LLM genera ‚Üí TTS ‚Üí Audio
# ‚Üí Latencia percibida: ~1.5s (filler oculta 2.3s reales)
```

---

## üìä KPIs Objetivo v2.17

| M√©trica | Objetivo | Componente |
|---------|----------|------------|
| **Latencia STT** | < 150ms/chunk | Vosk Streaming ‚úÖ |
| **Latencia Router** | < 30ms | LoRA Router ‚úÖ |
| **Latencia TRM** | < 50ms | TRM Classifier ‚è≥ |
| **Latencia LLM** | < 2.5s | LFM2 ‚è≥ |
| **Latencia percibida** | < 1.5s | Fillers ‚è≥ |
| **TRM Hit Rate** | > 40% | LoRA Router entrenado ‚è≥ |
| **RAG Coherencia** | > 90% | Capa 2 ‚è≥ |
| **CPU P99** | < 85% | LoRA Scheduler ‚è≥ |

---

## üöÄ Roadmap de Implementaci√≥n

### **‚úÖ Semana 1: Capa 1 Completa** (COMPLETADO - 30 Oct 2025)
- [x] Canal IN (vosk_streaming, lora_router, input_thread)
- [x] Canal OUT (output_thread)
- [x] Orquestador Capa 1
- [x] Test E2E Capa 1
- [x] Documentaci√≥n completa

**Logros:**
- ~1,719 l√≠neas de c√≥digo productivo
- 6 componentes nuevos totalmente funcionales
- Sistema full-duplex operativo
- TRM cache implementado (respuestas < 50ms)
- Integraci√≥n LFM2 completa

### **‚è≥ Semana 2: Capa 2 - RAG** (Estimado: 2 d√≠as)
- [ ] EmbeddingGemma wrapper
- [ ] Qdrant setup
- [ ] Conversation RAG
- [ ] Test interrupciones

### **Semana 3: Capa 3 - Fillers** (2 d√≠as)
- [ ] Generar coletillas con Piper
- [ ] Filler Manager
- [ ] Latency Detector
- [ ] Test fillers en conversaci√≥n

### **Semana 4: Capa 4 - Scheduler** (2 d√≠as)
- [ ] LoRA Scheduler
- [ ] Resource Monitor
- [ ] Test priorizaci√≥n din√°mica

### **Semana 5: Integraci√≥n Final** (3 d√≠as)
- [ ] Orquestador maestro
- [ ] Test E2E completo
- [ ] Benchmarking
- [ ] Optimizaci√≥n final

---

## üìÅ Estructura de Archivos Actual

```
core/
‚îú‚îÄ‚îÄ layer1_io/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ vosk_streaming.py           ‚úÖ (nuevo, 323 l√≠neas)
‚îÇ   ‚îú‚îÄ‚îÄ lora_router.py              ‚úÖ (nuevo, 384 l√≠neas)
‚îÇ   ‚îú‚îÄ‚îÄ input_thread.py             ‚úÖ (nuevo, 267 l√≠neas)
‚îÇ   ‚îú‚îÄ‚îÄ output_thread.py            ‚úÖ (nuevo, 386 l√≠neas)
‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.py             ‚úÖ (nuevo, 241 l√≠neas)
‚îÇ
‚îú‚îÄ‚îÄ layer2_memory/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ embedding_gemma.py          ‚è≥
‚îÇ   ‚îú‚îÄ‚îÄ qdrant_store.py             ‚è≥
‚îÇ   ‚îî‚îÄ‚îÄ conversation_rag.py         ‚è≥
‚îÇ
‚îú‚îÄ‚îÄ layer3_fluidity/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ filler_manager.py           ‚è≥
‚îÇ   ‚îú‚îÄ‚îÄ latency_detector.py         ‚è≥
‚îÇ   ‚îî‚îÄ‚îÄ generate_fillers.py         ‚è≥
‚îÇ
‚îú‚îÄ‚îÄ layer4_orchestration/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ lora_scheduler.py           ‚è≥
‚îÇ   ‚îî‚îÄ‚îÄ resource_monitor.py         ‚è≥
‚îÇ
‚îî‚îÄ‚îÄ orchestrator_fullduplex.py      ‚è≥ (orquestador maestro 4 capas)

assets/
‚îî‚îÄ‚îÄ fillers/                        ‚úÖ (dir creado)
    ‚îú‚îÄ‚îÄ hmm_01.wav                  ‚è≥
    ‚îú‚îÄ‚îÄ thinking_01.wav             ‚è≥
    ‚îú‚îÄ‚îÄ interesting_01.wav          ‚è≥
    ‚îî‚îÄ‚îÄ fillers.yaml                ‚è≥

tests/
‚îú‚îÄ‚îÄ test_layer1_fullduplex.py       ‚úÖ (nuevo, 118 l√≠neas)
‚îî‚îÄ‚îÄ test_fullduplex_complete.py     ‚è≥ (test 4 capas)

docs/
‚îú‚îÄ‚îÄ ARCHITECTURE_FULLDUPLEX_v2.17.md ‚úÖ
‚îî‚îÄ‚îÄ IMPLEMENTATION_PLAN_v2.17.md     ‚úÖ (este archivo)

state/
‚îî‚îÄ‚îÄ trm_cache.json                  ‚úÖ (generado autom√°ticamente)
```

---

## üîß Dependencias Adicionales Necesarias

```bash
# Ya instaladas:
# - vosk (v0.3.45) ‚úÖ
# - transformers ‚úÖ
# - torch ‚úÖ
# - numpy ‚úÖ

# Por instalar:
pip install qdrant-client          # Capa 2: BD vectorial
pip install sentence-transformers  # EmbeddingGemma (opcional)
pip install peft                   # LoRA training (Capa 4)
pip install psutil                 # Resource Monitor (Capa 4)
pip install sounddevice            # Test streaming (opcional)
```

---

## üìù Notas de Implementaci√≥n

### Canal IN (Completado):
- ‚úÖ VAD simple por energ√≠a (threshold=0.02)
- ‚úÖ Vosk streaming con detecci√≥n de fin por silencio (500ms)
- ‚úÖ BERT embeddings (768-dim)
- ‚úÖ LoRA Router con 3 clases (TRM/LLM/Traducir)
- ‚úÖ Estad√≠sticas en tiempo real

### Canal OUT (Pendiente):
- Coordinar con VAD de usuario (no interrumpir mientras habla)
- TTS streaming con Piper (chunks de 200ms)
- Buffer de respuesta proactivo (LLM genera ANTES de silencio)

### Capa 2 (Pendiente):
- Qdrant local (no cloud, privacidad)
- Indexar cada turno con timestamp
- Retrieval por similitud sem√°ntica (K=5)
- Recovery autom√°tico en interrupciones

### Capa 3 (Pendiente):
- Fillers con personalidad (voz de SARAi, no rob√≥ticos)
- Gap m√≠nimo 3s entre fillers (naturalidad)
- Predicci√≥n de latencia (no esperar timeout)

### Capa 4 (Pendiente):
- LoRA entrenado con logs de conversaciones reales
- Ajuste de prioridades cada 100ms
- Evitar thrashing (cambios muy frecuentes)

---

## ‚úÖ Pr√≥ximo Paso Inmediato

**Crear `output_thread.py` y completar Capa 1**

```python
# output_thread.py debe:
1. Esperar decisiones de input_thread
2. Si TRM ‚Üí Lookup en cache ‚Üí TTS inmediato
3. Si LLM ‚Üí LFM2 genera (streaming) ‚Üí Buffer ‚Üí Espera silencio ‚Üí TTS
4. Si Traducir ‚Üí NLLB ‚Üí LLM ‚Üí TTS
5. Coordinarse con Filler Manager (Capa 3)
```

---

**Estado: Capa 1 (Canal IN) ‚úÖ Completa y testeada**
**Siguiente: Capa 1 (Canal OUT) - Estimado 2-3 horas**
