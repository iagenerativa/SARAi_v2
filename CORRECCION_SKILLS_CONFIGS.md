# ‚úÖ CORRECCI√ìN FINAL: Skills como Configs (31 Oct 2025)

## üéØ Entendimiento Correcto

Los **skills NO son modelos LLM separados**, son **CONFIGURACIONES** que optimizan SOLAR/LFM2 para tareas espec√≠ficas.

### Ejemplo Real del Sistema

```yaml
# config/sarai.yaml
skills:
  programming:
    model: "solar"  # ‚Üê USA SOLAR EXISTENTE (no descarga CodeLlama)
    temperature: 0.2  # Precisi√≥n para c√≥digo
    max_tokens: 512
    system_prompt: |
      Eres un experto en programaci√≥n con 15 a√±os de experiencia.
      
      DIRECTRICES:
      - C√≥digo limpio, idiom√°tico y bien documentado
      - Explicaciones t√©cnicas precisas sin simplificaciones
      - Ejemplos ejecutables con manejo de errores
      - Referencia buenas pr√°cticas (PEP-8, SOLID, etc)
      
      FORMATO DE RESPUESTA:
      1. Explicaci√≥n breve (2-3 l√≠neas)
      2. C√≥digo con comentarios
      3. Ejemplo de uso
      4. Posibles edge cases
    domains: ["c√≥digo", "programaci√≥n", "python", "javascript", "debugging"]
```

## üèóÔ∏è Arquitectura Correcta

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Input: "¬øC√≥mo optimizo esta consulta SQL lenta?"            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TRM-Router (6 heads especializados)                         ‚îÇ
‚îÇ  - programming: 0.85 ‚≠ê GANADOR                              ‚îÇ
‚îÇ  - diagnosis: 0.45                                           ‚îÇ
‚îÇ  - finance: 0.05                                             ‚îÇ
‚îÇ  - creative: 0.02                                            ‚îÇ
‚îÇ  - reasoning: 0.35                                           ‚îÇ
‚îÇ  - general: 0.20                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MCP.select_skill_and_generate()                             ‚îÇ
‚îÇ  1. Selecciona: programming (score m√°s alto)                 ‚îÇ
‚îÇ  2. Carga: SKILL_CONFIGS["programming"]                      ‚îÇ
‚îÇ  3. Construye prompt especializado:                          ‚îÇ
‚îÇ     "Eres experto en programaci√≥n... [directrices]...        ‚îÇ
‚îÇ      ¬øC√≥mo optimizo SQL?"                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SOLAR-10.7B (YA en memoria)                                 ‚îÇ
‚îÇ  - temperature: 0.2 (precisi√≥n)                              ‚îÇ
‚îÇ  - max_tokens: 512                                           ‚îÇ
‚îÇ  - Genera con contexto de "experto en programaci√≥n"          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Respuesta Especializada:                                    ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ## An√°lisis de Optimizaci√≥n SQL                             ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  1. **Indexaci√≥n**:                                          ‚îÇ
‚îÇ     CREATE INDEX idx_user_created ON users(created_at);      ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  2. **EXPLAIN ANALYZE**:                                     ‚îÇ
‚îÇ     [an√°lisis t√©cnico detallado]                             ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  [respuesta t√©cnica precisa, estilo experto]                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìä Comparaci√≥n de Estrategias

| Aspecto | ‚ùå Skills MoE (Incorrecto) | ‚úÖ Skill Configs (Correcto) |
|---------|----------------------------|----------------------------|
| **Concepto** | 6 LLMs especializados | 6 configuraciones (prompts) |
| **Modelos en RAM** | 8 (SOLAR + LFM2 + 6 skills) | 2 (SOLAR + LFM2) |
| **RAM total** | ~11.6 GB | ~900 MB |
| **Latencia** | Alta (carga modelo) | Baja (modelo ya cargado) |
| **Especializaci√≥n** | Limitada al LLM | Profunda (prompts expertos) |
| **Ejemplos** | CodeLlama, Mistral, FinGPT | Prompt experto programaci√≥n |
| **Mantenibilidad** | Compleja (6 GGUFs) | Simple (editar YAML) |
| **Aprendizaje TRM** | No | S√≠ (mejora routing) |
| **LOC** | +970 | +765 (-205 neto) |

## üéØ Plan de Implementaci√≥n

### Semana 1 - Tickets Corregidos

#### T1.1-FINAL: Skill Configs + TRM Heads (8h)

**Archivos NUEVOS**:
- `core/skill_configs.py` (+180 LOC)
  ```python
  SKILL_CONFIGS = {
      "programming": {
          "model": "solar",
          "temperature": 0.2,
          "system_prompt": "Eres experto en programaci√≥n...",
          "domains": ["c√≥digo", "python", "debugging"]
      },
      # ... 5 m√°s
  }
  ```

- `scripts/generate_skill_dataset.py` (+200 LOC)
  - Genera 10K queries sint√©ticas clasificadas
  - Categories: programming, diagnosis, finance, creative, reasoning, general

- `scripts/train_trm_skills.py` (+150 LOC)
  - Entrena TRM-Router con 6 heads
  - Target accuracy: >85%

- `tests/test_skill_configs.py` (+120 LOC)
  - Valida estructura de configs
  - Tests por skill (6 √ó 2 = 12 tests)

**Archivos MODIFICADOS**:
- `core/trm_classifier.py` (+30 LOC)
  ```python
  class TRMClassifierSpecialized(nn.Module):
      def __init__(self):
          # ... recursi√≥n existente ...
          self.head_programming = nn.Linear(256, 1)
          self.head_diagnosis = nn.Linear(256, 1)
          self.head_finance = nn.Linear(256, 1)
          self.head_creative = nn.Linear(256, 1)
          self.head_reasoning = nn.Linear(256, 1)
          self.head_general = nn.Linear(256, 1)
  ```

- `core/mcp.py` (+60 LOC)
  ```python
  def select_skill_and_generate(self, trm_scores: dict, user_input: str) -> str:
      # 1. Seleccionar skill de mayor score
      best_skill = max(trm_scores.items(), key=lambda x: x[1])
      skill_name, confidence = best_skill
      
      # 2. Cargar config
      config = SKILL_CONFIGS[skill_name]
      
      # 3. Construir prompt especializado
      specialized_prompt = f"{config['system_prompt']}\n\n{user_input}"
      
      # 4. Generar con SOLAR/LFM2
      model = self.model_pool.get(config['model'])
      response = model.generate(
          specialized_prompt,
          temperature=config['temperature'],
          max_tokens=config['max_tokens']
      )
      
      return response
  ```

- `core/graph.py` (+25 LOC)
  - Integrar `select_skill_and_generate()` en nodos

**Total**: +765 LOC

#### T1.2-FINAL: MCP Skill Selection (6h)

**Objetivo**: Integrar skill selection en LangGraph

**Archivos**:
- `core/graph.py` (+40 LOC): Nodos especializados
- `core/feedback.py` (+25 LOC): Log skill metadata
- `tests/test_graph_skills.py` (+150 LOC): 6 tests E2E

**Total**: +215 LOC

#### T1.3-FINAL: MCP Continuous Learning (6h)

**Objetivo**: Ajustar skill routing basado en feedback

**Archivos**:
- `scripts/tune_trm_skills.py` (+100 LOC): Reentrenamiento nocturno
- `tests/test_mcp_learning.py` (+80 LOC): Tests de adaptaci√≥n

**Total**: +180 LOC

### Resumen de C√≥digo

**REVERTIR (Skills MoE incorrecto)**:
- `core/model_pool.py`: get_skill(), skills_cache (-150 LOC)
- `core/mcp.py`: execute_skills_moe() (-110 LOC)
- `tests/test_model_pool_skills.py`: Borrar (-320 LOC)
- `tests/test_mcp_skills.py`: Borrar (-300 LOC)
- **Subtotal**: -880 LOC

**CREAR (Skill Configs correcto)**:
- T1.1-FINAL: +765 LOC
- T1.2-FINAL: +215 LOC
- T1.3-FINAL: +180 LOC
- **Subtotal**: +1,160 LOC

**Balance neto**: +280 LOC (simplificaci√≥n + especializaci√≥n)

## üéì Lecciones Aprendidas

### ‚ùå Malentendido inicial
"Skills MoE = cargar CodeLlama, Mistral, FinGPT..."

### ‚úÖ Realidad del sistema
"Skills = prompts expertos + configuraciones √≥ptimas para SOLAR/LFM2"

### üí° Principio clave
> **Prompts especializados + TRM inteligente + 2 LLMs buenos >> 6 LLMs gen√©ricos de 7B**

### üéØ Beneficios reales

1. **RAM**: 900 MB vs 11.6 GB (ahorro 92%)
2. **Latencia**: Sin carga de modelos (SOLAR ya en memoria)
3. **Especializaci√≥n**: Prompts de experto >> LLM gen√©rico fine-tuned
4. **Mantenibilidad**: Editar YAML >> gestionar 6 GGUFs
5. **Aprendizaje**: TRM mejora routing con feedback

## ‚úÖ Pr√≥ximos Pasos Inmediatos

### Ma√±ana (1 Nov):

1. **Revertir c√≥digo incorrecto** (~2h):
   ```bash
   # Eliminar get_skill() de model_pool.py
   # Eliminar execute_skills_moe() de mcp.py
   # Borrar test_model_pool_skills.py
   # Borrar test_mcp_skills.py
   git add -A
   git commit -m "refactor: Revertir Skills MoE (eran configs, no LLMs)"
   ```

2. **Crear skill_configs.py** (~2h):
   - Diccionario con 6 configs especializados
   - System prompts expertos por dominio
   - Par√°metros √≥ptimos (temperature, max_tokens)

3. **Modificar TRM-Router** (~2h):
   - A√±adir 6 heads especializados
   - Forward pass retorna 6 scores

4. **Tests b√°sicos** (~2h):
   - Validar estructura de configs
   - Test por skill (12 total)

**ETA**: 8h (d√≠a completo)

---

**Firma**: SARAi Development Team  
**Fecha**: 31 Octubre 2025  
**Versi√≥n**: v2.12-alpha (estrategia corregida)  
**Status**: Skills como Configs ‚úÖ CORRECTO
